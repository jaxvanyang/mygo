{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2ad562-19ad-48c8-a261-8ece8cf76935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mygo.datasets import MCTSDataset\n",
    "from mygo.model import TinyModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ccf8f0-80f8-4185-a138-adff9822ee03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0cf68eebd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(25565)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79916dfc-c216-4f78-bca5-645e4c3351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MCTSDataset(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    transform=torch.from_numpy,\n",
    ")\n",
    "\n",
    "test_data = MCTSDataset(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    transform=torch.from_numpy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eaa5ab9-681e-4f54-a3c8-c5df7a0d721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    batches = len(dataloader)\n",
    "    model.train()\n",
    "    for i, (xs, ys) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(xs)\n",
    "        loss = loss_fn(pred, ys)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(f\"loss: {loss.item():>7f} [{i + 1:>2d}/{batches:>2d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0.0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xs, ys in dataloader:\n",
    "            pred = model(xs)\n",
    "            test_loss += loss_fn(pred, ys).item()\n",
    "            correct += (pred.argmax(1) == ys.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= batches\n",
    "    accuracy = correct / size * 100\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {accuracy:>.1f}%\\nAvg Loss: {test_loss:>7f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c90a3a-948a-4e3b-ae68-1f5d1a755fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyModel(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=81, bias=True)\n",
      "    (4): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "parameters: 456,545\n"
     ]
    }
   ],
   "source": [
    "model = TinyModel(9)\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201f15e0-5c40-42f3-84c5-9c4da7d7f447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------\n",
      "loss: 4.394397 [10/292]\n",
      "loss: 4.394379 [20/292]\n",
      "loss: 4.394395 [30/292]\n",
      "loss: 4.394384 [40/292]\n",
      "loss: 4.394180 [50/292]\n",
      "loss: 4.394292 [60/292]\n",
      "loss: 4.394122 [70/292]\n",
      "loss: 4.393923 [80/292]\n",
      "loss: 4.394064 [90/292]\n",
      "loss: 4.393973 [100/292]\n",
      "loss: 4.394046 [110/292]\n",
      "loss: 4.393663 [120/292]\n",
      "loss: 4.393711 [130/292]\n",
      "loss: 4.393630 [140/292]\n",
      "loss: 4.393457 [150/292]\n",
      "loss: 4.393137 [160/292]\n",
      "loss: 4.393414 [170/292]\n",
      "loss: 4.392933 [180/292]\n",
      "loss: 4.392430 [190/292]\n",
      "loss: 4.392473 [200/292]\n",
      "loss: 4.392848 [210/292]\n",
      "loss: 4.391551 [220/292]\n",
      "loss: 4.391968 [230/292]\n",
      "loss: 4.389781 [240/292]\n",
      "loss: 4.389716 [250/292]\n",
      "loss: 4.388471 [260/292]\n",
      "loss: 4.383140 [270/292]\n",
      "loss: 4.386102 [280/292]\n",
      "loss: 4.391413 [290/292]\n",
      "\n",
      "Test Accuracy: 2.4%\n",
      "Avg Loss: 4.386696\n",
      "\n",
      "Epoch 2\n",
      "-------------------------\n",
      "loss: 4.392581 [10/292]\n",
      "loss: 4.389024 [20/292]\n",
      "loss: 4.381825 [30/292]\n",
      "loss: 4.387025 [40/292]\n",
      "loss: 4.393531 [50/292]\n",
      "loss: 4.379637 [60/292]\n",
      "loss: 4.389768 [70/292]\n",
      "loss: 4.392833 [80/292]\n",
      "loss: 4.393899 [90/292]\n",
      "loss: 4.393716 [100/292]\n",
      "loss: 4.383408 [110/292]\n",
      "loss: 4.392737 [120/292]\n",
      "loss: 4.398857 [130/292]\n",
      "loss: 4.380999 [140/292]\n",
      "loss: 4.390257 [150/292]\n",
      "loss: 4.405618 [160/292]\n",
      "loss: 4.373734 [170/292]\n",
      "loss: 4.389390 [180/292]\n",
      "loss: 4.379482 [190/292]\n",
      "loss: 4.389735 [200/292]\n",
      "loss: 4.384072 [210/292]\n",
      "loss: 4.378600 [220/292]\n",
      "loss: 4.386540 [230/292]\n",
      "loss: 4.379017 [240/292]\n",
      "loss: 4.383224 [250/292]\n",
      "loss: 4.391508 [260/292]\n",
      "loss: 4.376960 [270/292]\n",
      "loss: 4.372419 [280/292]\n",
      "loss: 4.389893 [290/292]\n",
      "\n",
      "Test Accuracy: 2.3%\n",
      "Avg Loss: 4.385375\n",
      "\n",
      "Epoch 3\n",
      "-------------------------\n",
      "loss: 4.392123 [10/292]\n",
      "loss: 4.385305 [20/292]\n",
      "loss: 4.391417 [30/292]\n",
      "loss: 4.383705 [40/292]\n",
      "loss: 4.387856 [50/292]\n",
      "loss: 4.383475 [60/292]\n",
      "loss: 4.389951 [70/292]\n",
      "loss: 4.386651 [80/292]\n",
      "loss: 4.393636 [90/292]\n",
      "loss: 4.393468 [100/292]\n",
      "loss: 4.382112 [110/292]\n",
      "loss: 4.383244 [120/292]\n",
      "loss: 4.392176 [130/292]\n",
      "loss: 4.388725 [140/292]\n",
      "loss: 4.382166 [150/292]\n",
      "loss: 4.387931 [160/292]\n",
      "loss: 4.387826 [170/292]\n",
      "loss: 4.391468 [180/292]\n",
      "loss: 4.385750 [190/292]\n",
      "loss: 4.376417 [200/292]\n",
      "loss: 4.385787 [210/292]\n",
      "loss: 4.379419 [220/292]\n",
      "loss: 4.397673 [230/292]\n",
      "loss: 4.397590 [240/292]\n",
      "loss: 4.386674 [250/292]\n",
      "loss: 4.388047 [260/292]\n",
      "loss: 4.388288 [270/292]\n",
      "loss: 4.379167 [280/292]\n",
      "loss: 4.393908 [290/292]\n",
      "\n",
      "Test Accuracy: 2.3%\n",
      "Avg Loss: 4.384883\n",
      "\n",
      "Epoch 4\n",
      "-------------------------\n",
      "loss: 4.394756 [10/292]\n",
      "loss: 4.386748 [20/292]\n",
      "loss: 4.382061 [30/292]\n",
      "loss: 4.385462 [40/292]\n",
      "loss: 4.385682 [50/292]\n",
      "loss: 4.380297 [60/292]\n",
      "loss: 4.382383 [70/292]\n",
      "loss: 4.388679 [80/292]\n",
      "loss: 4.383546 [90/292]\n",
      "loss: 4.384851 [100/292]\n",
      "loss: 4.370723 [110/292]\n",
      "loss: 4.401240 [120/292]\n",
      "loss: 4.386905 [130/292]\n",
      "loss: 4.370590 [140/292]\n",
      "loss: 4.376283 [150/292]\n",
      "loss: 4.380713 [160/292]\n",
      "loss: 4.395581 [170/292]\n",
      "loss: 4.382380 [180/292]\n",
      "loss: 4.390126 [190/292]\n",
      "loss: 4.385305 [200/292]\n",
      "loss: 4.385826 [210/292]\n",
      "loss: 4.385736 [220/292]\n",
      "loss: 4.390736 [230/292]\n",
      "loss: 4.382478 [240/292]\n",
      "loss: 4.382395 [250/292]\n",
      "loss: 4.381731 [260/292]\n",
      "loss: 4.391549 [270/292]\n",
      "loss: 4.384994 [280/292]\n",
      "loss: 4.385545 [290/292]\n",
      "\n",
      "Test Accuracy: 2.4%\n",
      "Avg Loss: 4.384731\n",
      "\n",
      "Epoch 5\n",
      "-------------------------\n",
      "loss: 4.374374 [10/292]\n",
      "loss: 4.385170 [20/292]\n",
      "loss: 4.387710 [30/292]\n",
      "loss: 4.384521 [40/292]\n",
      "loss: 4.374353 [50/292]\n",
      "loss: 4.394067 [60/292]\n",
      "loss: 4.383767 [70/292]\n",
      "loss: 4.373743 [80/292]\n",
      "loss: 4.387803 [90/292]\n",
      "loss: 4.377961 [100/292]\n",
      "loss: 4.387887 [110/292]\n",
      "loss: 4.385688 [120/292]\n",
      "loss: 4.376074 [130/292]\n",
      "loss: 4.383151 [140/292]\n",
      "loss: 4.388228 [150/292]\n",
      "loss: 4.391006 [160/292]\n",
      "loss: 4.385710 [170/292]\n",
      "loss: 4.392388 [180/292]\n",
      "loss: 4.387060 [190/292]\n",
      "loss: 4.378485 [200/292]\n",
      "loss: 4.383386 [210/292]\n",
      "loss: 4.387630 [220/292]\n",
      "loss: 4.388871 [230/292]\n",
      "loss: 4.381199 [240/292]\n",
      "loss: 4.382183 [250/292]\n",
      "loss: 4.382740 [260/292]\n",
      "loss: 4.382103 [270/292]\n",
      "loss: 4.375572 [280/292]\n",
      "loss: 4.384617 [290/292]\n",
      "\n",
      "Test Accuracy: 2.5%\n",
      "Avg Loss: 4.383602\n",
      "\n",
      "Epoch 6\n",
      "-------------------------\n",
      "loss: 4.381790 [10/292]\n",
      "loss: 4.378947 [20/292]\n",
      "loss: 4.387945 [30/292]\n",
      "loss: 4.378774 [40/292]\n",
      "loss: 4.378126 [50/292]\n",
      "loss: 4.375982 [60/292]\n",
      "loss: 4.379748 [70/292]\n",
      "loss: 4.382502 [80/292]\n",
      "loss: 4.382146 [90/292]\n",
      "loss: 4.372511 [100/292]\n",
      "loss: 4.377107 [110/292]\n",
      "loss: 4.376655 [120/292]\n",
      "loss: 4.374223 [130/292]\n",
      "loss: 4.388603 [140/292]\n",
      "loss: 4.386863 [150/292]\n",
      "loss: 4.371077 [160/292]\n",
      "loss: 4.376951 [170/292]\n",
      "loss: 4.391595 [180/292]\n",
      "loss: 4.373642 [190/292]\n",
      "loss: 4.384116 [200/292]\n",
      "loss: 4.380471 [210/292]\n",
      "loss: 4.371917 [220/292]\n",
      "loss: 4.361363 [230/292]\n",
      "loss: 4.389945 [240/292]\n",
      "loss: 4.386340 [250/292]\n",
      "loss: 4.396941 [260/292]\n",
      "loss: 4.391830 [270/292]\n",
      "loss: 4.390883 [280/292]\n",
      "loss: 4.395476 [290/292]\n",
      "\n",
      "Test Accuracy: 2.8%\n",
      "Avg Loss: 4.382439\n",
      "\n",
      "Epoch 7\n",
      "-------------------------\n",
      "loss: 4.378845 [10/292]\n",
      "loss: 4.397979 [20/292]\n",
      "loss: 4.381632 [30/292]\n",
      "loss: 4.398512 [40/292]\n",
      "loss: 4.385062 [50/292]\n",
      "loss: 4.382911 [60/292]\n",
      "loss: 4.376381 [70/292]\n",
      "loss: 4.377355 [80/292]\n",
      "loss: 4.394317 [90/292]\n",
      "loss: 4.385120 [100/292]\n",
      "loss: 4.383748 [110/292]\n",
      "loss: 4.382496 [120/292]\n",
      "loss: 4.385140 [130/292]\n",
      "loss: 4.379776 [140/292]\n",
      "loss: 4.387790 [150/292]\n",
      "loss: 4.392355 [160/292]\n",
      "loss: 4.378539 [170/292]\n",
      "loss: 4.376379 [180/292]\n",
      "loss: 4.383682 [190/292]\n",
      "loss: 4.386857 [200/292]\n",
      "loss: 4.393578 [210/292]\n",
      "loss: 4.383111 [220/292]\n",
      "loss: 4.379876 [230/292]\n",
      "loss: 4.370680 [240/292]\n",
      "loss: 4.381053 [250/292]\n",
      "loss: 4.373547 [260/292]\n",
      "loss: 4.386346 [270/292]\n",
      "loss: 4.384025 [280/292]\n",
      "loss: 4.385444 [290/292]\n",
      "\n",
      "Test Accuracy: 2.6%\n",
      "Avg Loss: 4.383987\n",
      "\n",
      "Epoch 8\n",
      "-------------------------\n",
      "loss: 4.388072 [10/292]\n",
      "loss: 4.364208 [20/292]\n",
      "loss: 4.380939 [30/292]\n",
      "loss: 4.372878 [40/292]\n",
      "loss: 4.384461 [50/292]\n",
      "loss: 4.371486 [60/292]\n",
      "loss: 4.363800 [70/292]\n",
      "loss: 4.372269 [80/292]\n",
      "loss: 4.380476 [90/292]\n",
      "loss: 4.377833 [100/292]\n",
      "loss: 4.372531 [110/292]\n",
      "loss: 4.388687 [120/292]\n",
      "loss: 4.388850 [130/292]\n",
      "loss: 4.376912 [140/292]\n",
      "loss: 4.393431 [150/292]\n",
      "loss: 4.370687 [160/292]\n",
      "loss: 4.380423 [170/292]\n",
      "loss: 4.378695 [180/292]\n",
      "loss: 4.386552 [190/292]\n",
      "loss: 4.389447 [200/292]\n",
      "loss: 4.393128 [210/292]\n",
      "loss: 4.396716 [220/292]\n",
      "loss: 4.373341 [230/292]\n",
      "loss: 4.382157 [240/292]\n",
      "loss: 4.384198 [250/292]\n",
      "loss: 4.400645 [260/292]\n",
      "loss: 4.375862 [270/292]\n",
      "loss: 4.373265 [280/292]\n",
      "loss: 4.384311 [290/292]\n",
      "\n",
      "Test Accuracy: 3.0%\n",
      "Avg Loss: 4.383190\n",
      "\n",
      "Epoch 9\n",
      "-------------------------\n",
      "loss: 4.384435 [10/292]\n",
      "loss: 4.377225 [20/292]\n",
      "loss: 4.393311 [30/292]\n",
      "loss: 4.387843 [40/292]\n",
      "loss: 4.384676 [50/292]\n",
      "loss: 4.386887 [60/292]\n",
      "loss: 4.378397 [70/292]\n",
      "loss: 4.380866 [80/292]\n",
      "loss: 4.374242 [90/292]\n",
      "loss: 4.361247 [100/292]\n",
      "loss: 4.379891 [110/292]\n",
      "loss: 4.392828 [120/292]\n",
      "loss: 4.386932 [130/292]\n",
      "loss: 4.384587 [140/292]\n",
      "loss: 4.378063 [150/292]\n",
      "loss: 4.367873 [160/292]\n",
      "loss: 4.380349 [170/292]\n",
      "loss: 4.370236 [180/292]\n",
      "loss: 4.387560 [190/292]\n",
      "loss: 4.366327 [200/292]\n",
      "loss: 4.383608 [210/292]\n",
      "loss: 4.397053 [220/292]\n",
      "loss: 4.380822 [230/292]\n",
      "loss: 4.380801 [240/292]\n",
      "loss: 4.382896 [250/292]\n",
      "loss: 4.398864 [260/292]\n",
      "loss: 4.386425 [270/292]\n",
      "loss: 4.388057 [280/292]\n",
      "loss: 4.366519 [290/292]\n",
      "\n",
      "Test Accuracy: 2.7%\n",
      "Avg Loss: 4.380120\n",
      "\n",
      "Epoch 10\n",
      "-------------------------\n",
      "loss: 4.385879 [10/292]\n",
      "loss: 4.386167 [20/292]\n",
      "loss: 4.382537 [30/292]\n",
      "loss: 4.377696 [40/292]\n",
      "loss: 4.387954 [50/292]\n",
      "loss: 4.385983 [60/292]\n",
      "loss: 4.373581 [70/292]\n",
      "loss: 4.373010 [80/292]\n",
      "loss: 4.376050 [90/292]\n",
      "loss: 4.387947 [100/292]\n",
      "loss: 4.388122 [110/292]\n",
      "loss: 4.379797 [120/292]\n",
      "loss: 4.380582 [130/292]\n",
      "loss: 4.378282 [140/292]\n",
      "loss: 4.387716 [150/292]\n",
      "loss: 4.382780 [160/292]\n",
      "loss: 4.383805 [170/292]\n",
      "loss: 4.360701 [180/292]\n",
      "loss: 4.376688 [190/292]\n",
      "loss: 4.386169 [200/292]\n",
      "loss: 4.366825 [210/292]\n",
      "loss: 4.372888 [220/292]\n",
      "loss: 4.386684 [230/292]\n",
      "loss: 4.382617 [240/292]\n",
      "loss: 4.378371 [250/292]\n",
      "loss: 4.369772 [260/292]\n",
      "loss: 4.382289 [270/292]\n",
      "loss: 4.380807 [280/292]\n",
      "loss: 4.380741 [290/292]\n",
      "\n",
      "Test Accuracy: 3.0%\n",
      "Avg Loss: 4.381808\n",
      "\n",
      "Epoch 11\n",
      "-------------------------\n",
      "loss: 4.376883 [10/292]\n",
      "loss: 4.386057 [20/292]\n",
      "loss: 4.372390 [30/292]\n",
      "loss: 4.383128 [40/292]\n",
      "loss: 4.366845 [50/292]\n",
      "loss: 4.360951 [60/292]\n",
      "loss: 4.382244 [70/292]\n",
      "loss: 4.389619 [80/292]\n",
      "loss: 4.367364 [90/292]\n",
      "loss: 4.379796 [100/292]\n",
      "loss: 4.365800 [110/292]\n",
      "loss: 4.389962 [120/292]\n",
      "loss: 4.384395 [130/292]\n",
      "loss: 4.379557 [140/292]\n",
      "loss: 4.384971 [150/292]\n",
      "loss: 4.382040 [160/292]\n",
      "loss: 4.392820 [170/292]\n",
      "loss: 4.385428 [180/292]\n",
      "loss: 4.351061 [190/292]\n",
      "loss: 4.370460 [200/292]\n",
      "loss: 4.377665 [210/292]\n",
      "loss: 4.360489 [220/292]\n",
      "loss: 4.387324 [230/292]\n",
      "loss: 4.367668 [240/292]\n",
      "loss: 4.379117 [250/292]\n",
      "loss: 4.390843 [260/292]\n",
      "loss: 4.386598 [270/292]\n",
      "loss: 4.388699 [280/292]\n",
      "loss: 4.361874 [290/292]\n",
      "\n",
      "Test Accuracy: 3.6%\n",
      "Avg Loss: 4.376600\n",
      "\n",
      "Epoch 12\n",
      "-------------------------\n",
      "loss: 4.364587 [10/292]\n",
      "loss: 4.376505 [20/292]\n",
      "loss: 4.390471 [30/292]\n",
      "loss: 4.384171 [40/292]\n",
      "loss: 4.381025 [50/292]\n",
      "loss: 4.383305 [60/292]\n",
      "loss: 4.370796 [70/292]\n",
      "loss: 4.387587 [80/292]\n",
      "loss: 4.380677 [90/292]\n",
      "loss: 4.337872 [100/292]\n",
      "loss: 4.369283 [110/292]\n",
      "loss: 4.370565 [120/292]\n",
      "loss: 4.378942 [130/292]\n",
      "loss: 4.369035 [140/292]\n",
      "loss: 4.383205 [150/292]\n",
      "loss: 4.377105 [160/292]\n",
      "loss: 4.391912 [170/292]\n",
      "loss: 4.383194 [180/292]\n",
      "loss: 4.395026 [190/292]\n",
      "loss: 4.362045 [200/292]\n",
      "loss: 4.361606 [210/292]\n",
      "loss: 4.379081 [220/292]\n",
      "loss: 4.390557 [230/292]\n",
      "loss: 4.375131 [240/292]\n",
      "loss: 4.366502 [250/292]\n",
      "loss: 4.360812 [260/292]\n",
      "loss: 4.396354 [270/292]\n",
      "loss: 4.386122 [280/292]\n",
      "loss: 4.371673 [290/292]\n",
      "\n",
      "Test Accuracy: 3.3%\n",
      "Avg Loss: 4.378499\n",
      "\n",
      "Epoch 13\n",
      "-------------------------\n",
      "loss: 4.392982 [10/292]\n",
      "loss: 4.380816 [20/292]\n",
      "loss: 4.376328 [30/292]\n",
      "loss: 4.368642 [40/292]\n",
      "loss: 4.383532 [50/292]\n",
      "loss: 4.382531 [60/292]\n",
      "loss: 4.368332 [70/292]\n",
      "loss: 4.396842 [80/292]\n",
      "loss: 4.372077 [90/292]\n",
      "loss: 4.374801 [100/292]\n",
      "loss: 4.371270 [110/292]\n",
      "loss: 4.378099 [120/292]\n",
      "loss: 4.379137 [130/292]\n",
      "loss: 4.384241 [140/292]\n",
      "loss: 4.380978 [150/292]\n",
      "loss: 4.343768 [160/292]\n",
      "loss: 4.379588 [170/292]\n",
      "loss: 4.385553 [180/292]\n",
      "loss: 4.383004 [190/292]\n",
      "loss: 4.374221 [200/292]\n",
      "loss: 4.371942 [210/292]\n",
      "loss: 4.373745 [220/292]\n",
      "loss: 4.371499 [230/292]\n",
      "loss: 4.382529 [240/292]\n",
      "loss: 4.384190 [250/292]\n",
      "loss: 4.381207 [260/292]\n",
      "loss: 4.374158 [270/292]\n",
      "loss: 4.389210 [280/292]\n",
      "loss: 4.357696 [290/292]\n",
      "\n",
      "Test Accuracy: 3.6%\n",
      "Avg Loss: 4.375215\n",
      "\n",
      "Epoch 14\n",
      "-------------------------\n",
      "loss: 4.370426 [10/292]\n",
      "loss: 4.379391 [20/292]\n",
      "loss: 4.373332 [30/292]\n",
      "loss: 4.370128 [40/292]\n",
      "loss: 4.363680 [50/292]\n",
      "loss: 4.383505 [60/292]\n",
      "loss: 4.371860 [70/292]\n",
      "loss: 4.350807 [80/292]\n",
      "loss: 4.384594 [90/292]\n",
      "loss: 4.376915 [100/292]\n",
      "loss: 4.369261 [110/292]\n",
      "loss: 4.368267 [120/292]\n",
      "loss: 4.364850 [130/292]\n",
      "loss: 4.375483 [140/292]\n",
      "loss: 4.375999 [150/292]\n",
      "loss: 4.388428 [160/292]\n",
      "loss: 4.368265 [170/292]\n",
      "loss: 4.356923 [180/292]\n",
      "loss: 4.385681 [190/292]\n",
      "loss: 4.392041 [200/292]\n",
      "loss: 4.390299 [210/292]\n",
      "loss: 4.367460 [220/292]\n",
      "loss: 4.381574 [230/292]\n",
      "loss: 4.382148 [240/292]\n",
      "loss: 4.386077 [250/292]\n",
      "loss: 4.359270 [260/292]\n",
      "loss: 4.372178 [270/292]\n",
      "loss: 4.367320 [280/292]\n",
      "loss: 4.369943 [290/292]\n",
      "\n",
      "Test Accuracy: 4.0%\n",
      "Avg Loss: 4.371689\n",
      "\n",
      "Epoch 15\n",
      "-------------------------\n",
      "loss: 4.374331 [10/292]\n",
      "loss: 4.377061 [20/292]\n",
      "loss: 4.393939 [30/292]\n",
      "loss: 4.373936 [40/292]\n",
      "loss: 4.338381 [50/292]\n",
      "loss: 4.361589 [60/292]\n",
      "loss: 4.360321 [70/292]\n",
      "loss: 4.348381 [80/292]\n",
      "loss: 4.373118 [90/292]\n",
      "loss: 4.358464 [100/292]\n",
      "loss: 4.367353 [110/292]\n",
      "loss: 4.377992 [120/292]\n",
      "loss: 4.354417 [130/292]\n",
      "loss: 4.384448 [140/292]\n",
      "loss: 4.381906 [150/292]\n",
      "loss: 4.368232 [160/292]\n",
      "loss: 4.378473 [170/292]\n",
      "loss: 4.382924 [180/292]\n",
      "loss: 4.390069 [190/292]\n",
      "loss: 4.375304 [200/292]\n",
      "loss: 4.348642 [210/292]\n",
      "loss: 4.365546 [220/292]\n",
      "loss: 4.368256 [230/292]\n",
      "loss: 4.376570 [240/292]\n",
      "loss: 4.377253 [250/292]\n",
      "loss: 4.369682 [260/292]\n",
      "loss: 4.372011 [270/292]\n",
      "loss: 4.359447 [280/292]\n",
      "loss: 4.376299 [290/292]\n",
      "\n",
      "Test Accuracy: 3.9%\n",
      "Avg Loss: 4.373769\n",
      "\n",
      "Epoch 16\n",
      "-------------------------\n",
      "loss: 4.378754 [10/292]\n",
      "loss: 4.377252 [20/292]\n",
      "loss: 4.378225 [30/292]\n",
      "loss: 4.383617 [40/292]\n",
      "loss: 4.390834 [50/292]\n",
      "loss: 4.368114 [60/292]\n",
      "loss: 4.385168 [70/292]\n",
      "loss: 4.372395 [80/292]\n",
      "loss: 4.376866 [90/292]\n",
      "loss: 4.364611 [100/292]\n",
      "loss: 4.359023 [110/292]\n",
      "loss: 4.347958 [120/292]\n",
      "loss: 4.386056 [130/292]\n",
      "loss: 4.368439 [140/292]\n",
      "loss: 4.374032 [150/292]\n",
      "loss: 4.350010 [160/292]\n",
      "loss: 4.350524 [170/292]\n",
      "loss: 4.393848 [180/292]\n",
      "loss: 4.367785 [190/292]\n",
      "loss: 4.362597 [200/292]\n",
      "loss: 4.369117 [210/292]\n",
      "loss: 4.361306 [220/292]\n",
      "loss: 4.351451 [230/292]\n",
      "loss: 4.377196 [240/292]\n",
      "loss: 4.384832 [250/292]\n",
      "loss: 4.378866 [260/292]\n",
      "loss: 4.364779 [270/292]\n",
      "loss: 4.372448 [280/292]\n",
      "loss: 4.395578 [290/292]\n",
      "\n",
      "Test Accuracy: 4.6%\n",
      "Avg Loss: 4.370847\n",
      "\n",
      "Epoch 17\n",
      "-------------------------\n",
      "loss: 4.360376 [10/292]\n",
      "loss: 4.385169 [20/292]\n",
      "loss: 4.365351 [30/292]\n",
      "loss: 4.384094 [40/292]\n",
      "loss: 4.363820 [50/292]\n",
      "loss: 4.348498 [60/292]\n",
      "loss: 4.371315 [70/292]\n",
      "loss: 4.375882 [80/292]\n",
      "loss: 4.359976 [90/292]\n",
      "loss: 4.354865 [100/292]\n",
      "loss: 4.375630 [110/292]\n",
      "loss: 4.391004 [120/292]\n",
      "loss: 4.386268 [130/292]\n",
      "loss: 4.375890 [140/292]\n",
      "loss: 4.363962 [150/292]\n",
      "loss: 4.378786 [160/292]\n",
      "loss: 4.357299 [170/292]\n",
      "loss: 4.391724 [180/292]\n",
      "loss: 4.374877 [190/292]\n",
      "loss: 4.373760 [200/292]\n",
      "loss: 4.375812 [210/292]\n",
      "loss: 4.387310 [220/292]\n",
      "loss: 4.355049 [230/292]\n",
      "loss: 4.343643 [240/292]\n",
      "loss: 4.343225 [250/292]\n",
      "loss: 4.351276 [260/292]\n",
      "loss: 4.375651 [270/292]\n",
      "loss: 4.393666 [280/292]\n",
      "loss: 4.360881 [290/292]\n",
      "\n",
      "Test Accuracy: 4.4%\n",
      "Avg Loss: 4.371298\n",
      "\n",
      "Epoch 18\n",
      "-------------------------\n",
      "loss: 4.361190 [10/292]\n",
      "loss: 4.379896 [20/292]\n",
      "loss: 4.387452 [30/292]\n",
      "loss: 4.369193 [40/292]\n",
      "loss: 4.346584 [50/292]\n",
      "loss: 4.385798 [60/292]\n",
      "loss: 4.374557 [70/292]\n",
      "loss: 4.369257 [80/292]\n",
      "loss: 4.366679 [90/292]\n",
      "loss: 4.368892 [100/292]\n",
      "loss: 4.337339 [110/292]\n",
      "loss: 4.354087 [120/292]\n",
      "loss: 4.372874 [130/292]\n",
      "loss: 4.371299 [140/292]\n",
      "loss: 4.389393 [150/292]\n",
      "loss: 4.364425 [160/292]\n",
      "loss: 4.371239 [170/292]\n",
      "loss: 4.343822 [180/292]\n",
      "loss: 4.367462 [190/292]\n",
      "loss: 4.385537 [200/292]\n",
      "loss: 4.371475 [210/292]\n",
      "loss: 4.385241 [220/292]\n",
      "loss: 4.352818 [230/292]\n",
      "loss: 4.383406 [240/292]\n",
      "loss: 4.348634 [250/292]\n",
      "loss: 4.393682 [260/292]\n",
      "loss: 4.356438 [270/292]\n",
      "loss: 4.369210 [280/292]\n",
      "loss: 4.372652 [290/292]\n",
      "\n",
      "Test Accuracy: 4.2%\n",
      "Avg Loss: 4.371213\n",
      "\n",
      "Epoch 19\n",
      "-------------------------\n",
      "loss: 4.376976 [10/292]\n",
      "loss: 4.352394 [20/292]\n",
      "loss: 4.372775 [30/292]\n",
      "loss: 4.373479 [40/292]\n",
      "loss: 4.352707 [50/292]\n",
      "loss: 4.390812 [60/292]\n",
      "loss: 4.389957 [70/292]\n",
      "loss: 4.353820 [80/292]\n",
      "loss: 4.334092 [90/292]\n",
      "loss: 4.344905 [100/292]\n",
      "loss: 4.390415 [110/292]\n",
      "loss: 4.399082 [120/292]\n",
      "loss: 4.373725 [130/292]\n",
      "loss: 4.357796 [140/292]\n",
      "loss: 4.339590 [150/292]\n",
      "loss: 4.351579 [160/292]\n",
      "loss: 4.378509 [170/292]\n",
      "loss: 4.387320 [180/292]\n",
      "loss: 4.376200 [190/292]\n",
      "loss: 4.360413 [200/292]\n",
      "loss: 4.387992 [210/292]\n",
      "loss: 4.389953 [220/292]\n",
      "loss: 4.355029 [230/292]\n",
      "loss: 4.326109 [240/292]\n",
      "loss: 4.380774 [250/292]\n",
      "loss: 4.369149 [260/292]\n",
      "loss: 4.383249 [270/292]\n",
      "loss: 4.365270 [280/292]\n",
      "loss: 4.377154 [290/292]\n",
      "\n",
      "Test Accuracy: 4.6%\n",
      "Avg Loss: 4.370099\n",
      "\n",
      "Epoch 20\n",
      "-------------------------\n",
      "loss: 4.371612 [10/292]\n",
      "loss: 4.368538 [20/292]\n",
      "loss: 4.370460 [30/292]\n",
      "loss: 4.374268 [40/292]\n",
      "loss: 4.373192 [50/292]\n",
      "loss: 4.343286 [60/292]\n",
      "loss: 4.378921 [70/292]\n",
      "loss: 4.375757 [80/292]\n",
      "loss: 4.382290 [90/292]\n",
      "loss: 4.370078 [100/292]\n",
      "loss: 4.395084 [110/292]\n",
      "loss: 4.394082 [120/292]\n",
      "loss: 4.381077 [130/292]\n",
      "loss: 4.336140 [140/292]\n",
      "loss: 4.347918 [150/292]\n",
      "loss: 4.355018 [160/292]\n",
      "loss: 4.348112 [170/292]\n",
      "loss: 4.367695 [180/292]\n",
      "loss: 4.386638 [190/292]\n",
      "loss: 4.378060 [200/292]\n",
      "loss: 4.367509 [210/292]\n",
      "loss: 4.365062 [220/292]\n",
      "loss: 4.387836 [230/292]\n",
      "loss: 4.379971 [240/292]\n",
      "loss: 4.373484 [250/292]\n",
      "loss: 4.389812 [260/292]\n",
      "loss: 4.359118 [270/292]\n",
      "loss: 4.360379 [280/292]\n",
      "loss: 4.353446 [290/292]\n",
      "\n",
      "Test Accuracy: 4.6%\n",
      "Avg Loss: 4.367994\n",
      "\n",
      "Epoch 21\n",
      "-------------------------\n",
      "loss: 4.389287 [10/292]\n",
      "loss: 4.353662 [20/292]\n",
      "loss: 4.383821 [30/292]\n",
      "loss: 4.354891 [40/292]\n",
      "loss: 4.396544 [50/292]\n",
      "loss: 4.387494 [60/292]\n",
      "loss: 4.389800 [70/292]\n",
      "loss: 4.378714 [80/292]\n",
      "loss: 4.384780 [90/292]\n",
      "loss: 4.374553 [100/292]\n",
      "loss: 4.376310 [110/292]\n",
      "loss: 4.376200 [120/292]\n",
      "loss: 4.359230 [130/292]\n",
      "loss: 4.369095 [140/292]\n",
      "loss: 4.367413 [150/292]\n",
      "loss: 4.372524 [160/292]\n",
      "loss: 4.379721 [170/292]\n",
      "loss: 4.334013 [180/292]\n",
      "loss: 4.388310 [190/292]\n",
      "loss: 4.385138 [200/292]\n",
      "loss: 4.375305 [210/292]\n",
      "loss: 4.353966 [220/292]\n",
      "loss: 4.346427 [230/292]\n",
      "loss: 4.353077 [240/292]\n",
      "loss: 4.362954 [250/292]\n",
      "loss: 4.366938 [260/292]\n",
      "loss: 4.377759 [270/292]\n",
      "loss: 4.361198 [280/292]\n",
      "loss: 4.357191 [290/292]\n",
      "\n",
      "Test Accuracy: 5.0%\n",
      "Avg Loss: 4.366164\n",
      "\n",
      "Epoch 22\n",
      "-------------------------\n",
      "loss: 4.370529 [10/292]\n",
      "loss: 4.332366 [20/292]\n",
      "loss: 4.363170 [30/292]\n",
      "loss: 4.363438 [40/292]\n",
      "loss: 4.374455 [50/292]\n",
      "loss: 4.393481 [60/292]\n",
      "loss: 4.356342 [70/292]\n",
      "loss: 4.375064 [80/292]\n",
      "loss: 4.379217 [90/292]\n",
      "loss: 4.363755 [100/292]\n",
      "loss: 4.381229 [110/292]\n",
      "loss: 4.396654 [120/292]\n",
      "loss: 4.371284 [130/292]\n",
      "loss: 4.361011 [140/292]\n",
      "loss: 4.342371 [150/292]\n",
      "loss: 4.378035 [160/292]\n",
      "loss: 4.378968 [170/292]\n",
      "loss: 4.368793 [180/292]\n",
      "loss: 4.353227 [190/292]\n",
      "loss: 4.366832 [200/292]\n",
      "loss: 4.347982 [210/292]\n",
      "loss: 4.369352 [220/292]\n",
      "loss: 4.377936 [230/292]\n",
      "loss: 4.319932 [240/292]\n",
      "loss: 4.339112 [250/292]\n",
      "loss: 4.386765 [260/292]\n",
      "loss: 4.374660 [270/292]\n",
      "loss: 4.362038 [280/292]\n",
      "loss: 4.362278 [290/292]\n",
      "\n",
      "Test Accuracy: 4.9%\n",
      "Avg Loss: 4.365569\n",
      "\n",
      "Epoch 23\n",
      "-------------------------\n",
      "loss: 4.370777 [10/292]\n",
      "loss: 4.369726 [20/292]\n",
      "loss: 4.343010 [30/292]\n",
      "loss: 4.348923 [40/292]\n",
      "loss: 4.369644 [50/292]\n",
      "loss: 4.375216 [60/292]\n",
      "loss: 4.367358 [70/292]\n",
      "loss: 4.351844 [80/292]\n",
      "loss: 4.365646 [90/292]\n",
      "loss: 4.347683 [100/292]\n",
      "loss: 4.362452 [110/292]\n",
      "loss: 4.372105 [120/292]\n",
      "loss: 4.346839 [130/292]\n",
      "loss: 4.362880 [140/292]\n",
      "loss: 4.360552 [150/292]\n",
      "loss: 4.340299 [160/292]\n",
      "loss: 4.361195 [170/292]\n",
      "loss: 4.365189 [180/292]\n",
      "loss: 4.386182 [190/292]\n",
      "loss: 4.364234 [200/292]\n",
      "loss: 4.353907 [210/292]\n",
      "loss: 4.367614 [220/292]\n",
      "loss: 4.360835 [230/292]\n",
      "loss: 4.365711 [240/292]\n",
      "loss: 4.382651 [250/292]\n",
      "loss: 4.357227 [260/292]\n",
      "loss: 4.365868 [270/292]\n",
      "loss: 4.370755 [280/292]\n",
      "loss: 4.387096 [290/292]\n",
      "\n",
      "Test Accuracy: 4.8%\n",
      "Avg Loss: 4.364820\n",
      "\n",
      "Epoch 24\n",
      "-------------------------\n",
      "loss: 4.340376 [10/292]\n",
      "loss: 4.371264 [20/292]\n",
      "loss: 4.388554 [30/292]\n",
      "loss: 4.360107 [40/292]\n",
      "loss: 4.363983 [50/292]\n",
      "loss: 4.385145 [60/292]\n",
      "loss: 4.353129 [70/292]\n",
      "loss: 4.392003 [80/292]\n",
      "loss: 4.382139 [90/292]\n",
      "loss: 4.383396 [100/292]\n",
      "loss: 4.352027 [110/292]\n",
      "loss: 4.367734 [120/292]\n",
      "loss: 4.382645 [130/292]\n",
      "loss: 4.365515 [140/292]\n",
      "loss: 4.363334 [150/292]\n",
      "loss: 4.383110 [160/292]\n",
      "loss: 4.383258 [170/292]\n",
      "loss: 4.379072 [180/292]\n",
      "loss: 4.367941 [190/292]\n",
      "loss: 4.327230 [200/292]\n",
      "loss: 4.398501 [210/292]\n",
      "loss: 4.335848 [220/292]\n",
      "loss: 4.358672 [230/292]\n",
      "loss: 4.388496 [240/292]\n",
      "loss: 4.371412 [250/292]\n",
      "loss: 4.322281 [260/292]\n",
      "loss: 4.376423 [270/292]\n",
      "loss: 4.386080 [280/292]\n",
      "loss: 4.331988 [290/292]\n",
      "\n",
      "Test Accuracy: 5.1%\n",
      "Avg Loss: 4.364651\n",
      "\n",
      "Epoch 25\n",
      "-------------------------\n",
      "loss: 4.360862 [10/292]\n",
      "loss: 4.365170 [20/292]\n",
      "loss: 4.344065 [30/292]\n",
      "loss: 4.345878 [40/292]\n",
      "loss: 4.370443 [50/292]\n",
      "loss: 4.346243 [60/292]\n",
      "loss: 4.357248 [70/292]\n",
      "loss: 4.365494 [80/292]\n",
      "loss: 4.377983 [90/292]\n",
      "loss: 4.370255 [100/292]\n",
      "loss: 4.373285 [110/292]\n",
      "loss: 4.339904 [120/292]\n",
      "loss: 4.353203 [130/292]\n",
      "loss: 4.352232 [140/292]\n",
      "loss: 4.360559 [150/292]\n",
      "loss: 4.396495 [160/292]\n",
      "loss: 4.362945 [170/292]\n",
      "loss: 4.387082 [180/292]\n",
      "loss: 4.374538 [190/292]\n",
      "loss: 4.366084 [200/292]\n",
      "loss: 4.391458 [210/292]\n",
      "loss: 4.363534 [220/292]\n",
      "loss: 4.392455 [230/292]\n",
      "loss: 4.365840 [240/292]\n",
      "loss: 4.335165 [250/292]\n",
      "loss: 4.368822 [260/292]\n",
      "loss: 4.369555 [270/292]\n",
      "loss: 4.395806 [280/292]\n",
      "loss: 4.364851 [290/292]\n",
      "\n",
      "Test Accuracy: 5.1%\n",
      "Avg Loss: 4.363401\n",
      "\n",
      "Epoch 26\n",
      "-------------------------\n",
      "loss: 4.379635 [10/292]\n",
      "loss: 4.372531 [20/292]\n",
      "loss: 4.372664 [30/292]\n",
      "loss: 4.360373 [40/292]\n",
      "loss: 4.366711 [50/292]\n",
      "loss: 4.359039 [60/292]\n",
      "loss: 4.370700 [70/292]\n",
      "loss: 4.404877 [80/292]\n",
      "loss: 4.353400 [90/292]\n",
      "loss: 4.337637 [100/292]\n",
      "loss: 4.360019 [110/292]\n",
      "loss: 4.359735 [120/292]\n",
      "loss: 4.373190 [130/292]\n",
      "loss: 4.340275 [140/292]\n",
      "loss: 4.352778 [150/292]\n",
      "loss: 4.359250 [160/292]\n",
      "loss: 4.350643 [170/292]\n",
      "loss: 4.376157 [180/292]\n",
      "loss: 4.388086 [190/292]\n",
      "loss: 4.338934 [200/292]\n",
      "loss: 4.370379 [210/292]\n",
      "loss: 4.371624 [220/292]\n",
      "loss: 4.361817 [230/292]\n",
      "loss: 4.363443 [240/292]\n",
      "loss: 4.354793 [250/292]\n",
      "loss: 4.368535 [260/292]\n",
      "loss: 4.359385 [270/292]\n",
      "loss: 4.337753 [280/292]\n",
      "loss: 4.369690 [290/292]\n",
      "\n",
      "Test Accuracy: 5.2%\n",
      "Avg Loss: 4.363481\n",
      "\n",
      "Epoch 27\n",
      "-------------------------\n",
      "loss: 4.343534 [10/292]\n",
      "loss: 4.356727 [20/292]\n",
      "loss: 4.376927 [30/292]\n",
      "loss: 4.370628 [40/292]\n",
      "loss: 4.371318 [50/292]\n",
      "loss: 4.349891 [60/292]\n",
      "loss: 4.371558 [70/292]\n",
      "loss: 4.365958 [80/292]\n",
      "loss: 4.359391 [90/292]\n",
      "loss: 4.374643 [100/292]\n",
      "loss: 4.390107 [110/292]\n",
      "loss: 4.325964 [120/292]\n",
      "loss: 4.372162 [130/292]\n",
      "loss: 4.357423 [140/292]\n",
      "loss: 4.350226 [150/292]\n",
      "loss: 4.317416 [160/292]\n",
      "loss: 4.347047 [170/292]\n",
      "loss: 4.392141 [180/292]\n",
      "loss: 4.352507 [190/292]\n",
      "loss: 4.360074 [200/292]\n",
      "loss: 4.354158 [210/292]\n",
      "loss: 4.382507 [220/292]\n",
      "loss: 4.367160 [230/292]\n",
      "loss: 4.352332 [240/292]\n",
      "loss: 4.371651 [250/292]\n",
      "loss: 4.394249 [260/292]\n",
      "loss: 4.357377 [270/292]\n",
      "loss: 4.345271 [280/292]\n",
      "loss: 4.380248 [290/292]\n",
      "\n",
      "Test Accuracy: 4.8%\n",
      "Avg Loss: 4.364465\n",
      "\n",
      "Epoch 28\n",
      "-------------------------\n",
      "loss: 4.354697 [10/292]\n",
      "loss: 4.334524 [20/292]\n",
      "loss: 4.362347 [30/292]\n",
      "loss: 4.338884 [40/292]\n",
      "loss: 4.385783 [50/292]\n",
      "loss: 4.358627 [60/292]\n",
      "loss: 4.395055 [70/292]\n",
      "loss: 4.370155 [80/292]\n",
      "loss: 4.360293 [90/292]\n",
      "loss: 4.383235 [100/292]\n",
      "loss: 4.346404 [110/292]\n",
      "loss: 4.355991 [120/292]\n",
      "loss: 4.379714 [130/292]\n",
      "loss: 4.357244 [140/292]\n",
      "loss: 4.347471 [150/292]\n",
      "loss: 4.372132 [160/292]\n",
      "loss: 4.344960 [170/292]\n",
      "loss: 4.363092 [180/292]\n",
      "loss: 4.335773 [190/292]\n",
      "loss: 4.363887 [200/292]\n",
      "loss: 4.358082 [210/292]\n",
      "loss: 4.355603 [220/292]\n",
      "loss: 4.349978 [230/292]\n",
      "loss: 4.388804 [240/292]\n",
      "loss: 4.380510 [250/292]\n",
      "loss: 4.357988 [260/292]\n",
      "loss: 4.342102 [270/292]\n",
      "loss: 4.367014 [280/292]\n",
      "loss: 4.354661 [290/292]\n",
      "\n",
      "Test Accuracy: 5.3%\n",
      "Avg Loss: 4.361185\n",
      "\n",
      "Epoch 29\n",
      "-------------------------\n",
      "loss: 4.366961 [10/292]\n",
      "loss: 4.344691 [20/292]\n",
      "loss: 4.378626 [30/292]\n",
      "loss: 4.350392 [40/292]\n",
      "loss: 4.382220 [50/292]\n",
      "loss: 4.380915 [60/292]\n",
      "loss: 4.354628 [70/292]\n",
      "loss: 4.363383 [80/292]\n",
      "loss: 4.369710 [90/292]\n",
      "loss: 4.396733 [100/292]\n",
      "loss: 4.343886 [110/292]\n",
      "loss: 4.334092 [120/292]\n",
      "loss: 4.364523 [130/292]\n",
      "loss: 4.358027 [140/292]\n",
      "loss: 4.347595 [150/292]\n",
      "loss: 4.387526 [160/292]\n",
      "loss: 4.368670 [170/292]\n",
      "loss: 4.369975 [180/292]\n",
      "loss: 4.380038 [190/292]\n",
      "loss: 4.374169 [200/292]\n",
      "loss: 4.381657 [210/292]\n",
      "loss: 4.378024 [220/292]\n",
      "loss: 4.367644 [230/292]\n",
      "loss: 4.371500 [240/292]\n",
      "loss: 4.348961 [250/292]\n",
      "loss: 4.354884 [260/292]\n",
      "loss: 4.376720 [270/292]\n",
      "loss: 4.351903 [280/292]\n",
      "loss: 4.399915 [290/292]\n",
      "\n",
      "Test Accuracy: 5.3%\n",
      "Avg Loss: 4.361883\n",
      "\n",
      "Epoch 30\n",
      "-------------------------\n",
      "loss: 4.301977 [10/292]\n",
      "loss: 4.365394 [20/292]\n",
      "loss: 4.346405 [30/292]\n",
      "loss: 4.383669 [40/292]\n",
      "loss: 4.361121 [50/292]\n",
      "loss: 4.390362 [60/292]\n",
      "loss: 4.335819 [70/292]\n",
      "loss: 4.373226 [80/292]\n",
      "loss: 4.375233 [90/292]\n",
      "loss: 4.333198 [100/292]\n",
      "loss: 4.333561 [110/292]\n",
      "loss: 4.368589 [120/292]\n",
      "loss: 4.362286 [130/292]\n",
      "loss: 4.368889 [140/292]\n",
      "loss: 4.351927 [150/292]\n",
      "loss: 4.372180 [160/292]\n",
      "loss: 4.370777 [170/292]\n",
      "loss: 4.376571 [180/292]\n",
      "loss: 4.353027 [190/292]\n",
      "loss: 4.359654 [200/292]\n",
      "loss: 4.314650 [210/292]\n",
      "loss: 4.357421 [220/292]\n",
      "loss: 4.332069 [230/292]\n",
      "loss: 4.373924 [240/292]\n",
      "loss: 4.338883 [250/292]\n",
      "loss: 4.362673 [260/292]\n",
      "loss: 4.371337 [270/292]\n",
      "loss: 4.336451 [280/292]\n",
      "loss: 4.367328 [290/292]\n",
      "\n",
      "Test Accuracy: 5.0%\n",
      "Avg Loss: 4.362945\n",
      "\n",
      "Epoch 31\n",
      "-------------------------\n",
      "loss: 4.359279 [10/292]\n",
      "loss: 4.326034 [20/292]\n",
      "loss: 4.363389 [30/292]\n",
      "loss: 4.338719 [40/292]\n",
      "loss: 4.335364 [50/292]\n",
      "loss: 4.356838 [60/292]\n",
      "loss: 4.359864 [70/292]\n",
      "loss: 4.364433 [80/292]\n",
      "loss: 4.339266 [90/292]\n",
      "loss: 4.372805 [100/292]\n",
      "loss: 4.379811 [110/292]\n",
      "loss: 4.340218 [120/292]\n",
      "loss: 4.380369 [130/292]\n",
      "loss: 4.368080 [140/292]\n",
      "loss: 4.361134 [150/292]\n",
      "loss: 4.343564 [160/292]\n",
      "loss: 4.371979 [170/292]\n",
      "loss: 4.368548 [180/292]\n",
      "loss: 4.394968 [190/292]\n",
      "loss: 4.339144 [200/292]\n",
      "loss: 4.385344 [210/292]\n",
      "loss: 4.345265 [220/292]\n",
      "loss: 4.336220 [230/292]\n",
      "loss: 4.348533 [240/292]\n",
      "loss: 4.348508 [250/292]\n",
      "loss: 4.343624 [260/292]\n",
      "loss: 4.375330 [270/292]\n",
      "loss: 4.351126 [280/292]\n",
      "loss: 4.366672 [290/292]\n",
      "\n",
      "Test Accuracy: 5.7%\n",
      "Avg Loss: 4.358782\n",
      "\n",
      "Epoch 32\n",
      "-------------------------\n",
      "loss: 4.386189 [10/292]\n",
      "loss: 4.347692 [20/292]\n",
      "loss: 4.339896 [30/292]\n",
      "loss: 4.361619 [40/292]\n",
      "loss: 4.368892 [50/292]\n",
      "loss: 4.371161 [60/292]\n",
      "loss: 4.337524 [70/292]\n",
      "loss: 4.358185 [80/292]\n",
      "loss: 4.379464 [90/292]\n",
      "loss: 4.363242 [100/292]\n",
      "loss: 4.376300 [110/292]\n",
      "loss: 4.350113 [120/292]\n",
      "loss: 4.324537 [130/292]\n",
      "loss: 4.374286 [140/292]\n",
      "loss: 4.334296 [150/292]\n",
      "loss: 4.330809 [160/292]\n",
      "loss: 4.374627 [170/292]\n",
      "loss: 4.354749 [180/292]\n",
      "loss: 4.361645 [190/292]\n",
      "loss: 4.373397 [200/292]\n",
      "loss: 4.357581 [210/292]\n",
      "loss: 4.350822 [220/292]\n",
      "loss: 4.350768 [230/292]\n",
      "loss: 4.356029 [240/292]\n",
      "loss: 4.375775 [250/292]\n",
      "loss: 4.367810 [260/292]\n",
      "loss: 4.352109 [270/292]\n",
      "loss: 4.341943 [280/292]\n",
      "loss: 4.362399 [290/292]\n",
      "\n",
      "Test Accuracy: 5.4%\n",
      "Avg Loss: 4.361470\n",
      "\n",
      "Epoch 33\n",
      "-------------------------\n",
      "loss: 4.333610 [10/292]\n",
      "loss: 4.361401 [20/292]\n",
      "loss: 4.349714 [30/292]\n",
      "loss: 4.355756 [40/292]\n",
      "loss: 4.348254 [50/292]\n",
      "loss: 4.346637 [60/292]\n",
      "loss: 4.352493 [70/292]\n",
      "loss: 4.375960 [80/292]\n",
      "loss: 4.380567 [90/292]\n",
      "loss: 4.332212 [100/292]\n",
      "loss: 4.366903 [110/292]\n",
      "loss: 4.373796 [120/292]\n",
      "loss: 4.331939 [130/292]\n",
      "loss: 4.360037 [140/292]\n",
      "loss: 4.361629 [150/292]\n",
      "loss: 4.364460 [160/292]\n",
      "loss: 4.373294 [170/292]\n",
      "loss: 4.344707 [180/292]\n",
      "loss: 4.340639 [190/292]\n",
      "loss: 4.308205 [200/292]\n",
      "loss: 4.364524 [210/292]\n",
      "loss: 4.346086 [220/292]\n",
      "loss: 4.361541 [230/292]\n",
      "loss: 4.372773 [240/292]\n",
      "loss: 4.343123 [250/292]\n",
      "loss: 4.380203 [260/292]\n",
      "loss: 4.375933 [270/292]\n",
      "loss: 4.348712 [280/292]\n",
      "loss: 4.357011 [290/292]\n",
      "\n",
      "Test Accuracy: 5.8%\n",
      "Avg Loss: 4.357739\n",
      "\n",
      "Epoch 34\n",
      "-------------------------\n",
      "loss: 4.385114 [10/292]\n",
      "loss: 4.342965 [20/292]\n",
      "loss: 4.328454 [30/292]\n",
      "loss: 4.361657 [40/292]\n",
      "loss: 4.342500 [50/292]\n",
      "loss: 4.357919 [60/292]\n",
      "loss: 4.390173 [70/292]\n",
      "loss: 4.363153 [80/292]\n",
      "loss: 4.375657 [90/292]\n",
      "loss: 4.332355 [100/292]\n",
      "loss: 4.354934 [110/292]\n",
      "loss: 4.357432 [120/292]\n",
      "loss: 4.372901 [130/292]\n",
      "loss: 4.333999 [140/292]\n",
      "loss: 4.346027 [150/292]\n",
      "loss: 4.354369 [160/292]\n",
      "loss: 4.374215 [170/292]\n",
      "loss: 4.356569 [180/292]\n",
      "loss: 4.368407 [190/292]\n",
      "loss: 4.344054 [200/292]\n",
      "loss: 4.365564 [210/292]\n",
      "loss: 4.376548 [220/292]\n",
      "loss: 4.351916 [230/292]\n",
      "loss: 4.366617 [240/292]\n",
      "loss: 4.369091 [250/292]\n",
      "loss: 4.394711 [260/292]\n",
      "loss: 4.364436 [270/292]\n",
      "loss: 4.378716 [280/292]\n",
      "loss: 4.381012 [290/292]\n",
      "\n",
      "Test Accuracy: 5.7%\n",
      "Avg Loss: 4.357072\n",
      "\n",
      "Epoch 35\n",
      "-------------------------\n",
      "loss: 4.370544 [10/292]\n",
      "loss: 4.368309 [20/292]\n",
      "loss: 4.366087 [30/292]\n",
      "loss: 4.362215 [40/292]\n",
      "loss: 4.348280 [50/292]\n",
      "loss: 4.389872 [60/292]\n",
      "loss: 4.354254 [70/292]\n",
      "loss: 4.366121 [80/292]\n",
      "loss: 4.368761 [90/292]\n",
      "loss: 4.331758 [100/292]\n",
      "loss: 4.382880 [110/292]\n",
      "loss: 4.395765 [120/292]\n",
      "loss: 4.363227 [130/292]\n",
      "loss: 4.370582 [140/292]\n",
      "loss: 4.371177 [150/292]\n",
      "loss: 4.329928 [160/292]\n",
      "loss: 4.353096 [170/292]\n",
      "loss: 4.353748 [180/292]\n",
      "loss: 4.360134 [190/292]\n",
      "loss: 4.371245 [200/292]\n",
      "loss: 4.364385 [210/292]\n",
      "loss: 4.384849 [220/292]\n",
      "loss: 4.346622 [230/292]\n",
      "loss: 4.396606 [240/292]\n",
      "loss: 4.347379 [250/292]\n",
      "loss: 4.374118 [260/292]\n",
      "loss: 4.362505 [270/292]\n",
      "loss: 4.357667 [280/292]\n",
      "loss: 4.372761 [290/292]\n",
      "\n",
      "Test Accuracy: 5.7%\n",
      "Avg Loss: 4.358970\n",
      "\n",
      "Epoch 36\n",
      "-------------------------\n",
      "loss: 4.365218 [10/292]\n",
      "loss: 4.367373 [20/292]\n",
      "loss: 4.328353 [30/292]\n",
      "loss: 4.354937 [40/292]\n",
      "loss: 4.379147 [50/292]\n",
      "loss: 4.357327 [60/292]\n",
      "loss: 4.333066 [70/292]\n",
      "loss: 4.362094 [80/292]\n",
      "loss: 4.346419 [90/292]\n",
      "loss: 4.352079 [100/292]\n",
      "loss: 4.350008 [110/292]\n",
      "loss: 4.380165 [120/292]\n",
      "loss: 4.355714 [130/292]\n",
      "loss: 4.380047 [140/292]\n",
      "loss: 4.373850 [150/292]\n",
      "loss: 4.364657 [160/292]\n",
      "loss: 4.368611 [170/292]\n",
      "loss: 4.360078 [180/292]\n",
      "loss: 4.325163 [190/292]\n",
      "loss: 4.378015 [200/292]\n",
      "loss: 4.355436 [210/292]\n",
      "loss: 4.348268 [220/292]\n",
      "loss: 4.362937 [230/292]\n",
      "loss: 4.377449 [240/292]\n",
      "loss: 4.358502 [250/292]\n",
      "loss: 4.347072 [260/292]\n",
      "loss: 4.328933 [270/292]\n",
      "loss: 4.358983 [280/292]\n",
      "loss: 4.349006 [290/292]\n",
      "\n",
      "Test Accuracy: 5.7%\n",
      "Avg Loss: 4.354998\n",
      "\n",
      "Epoch 37\n",
      "-------------------------\n",
      "loss: 4.358811 [10/292]\n",
      "loss: 4.359447 [20/292]\n",
      "loss: 4.335035 [30/292]\n",
      "loss: 4.352858 [40/292]\n",
      "loss: 4.346113 [50/292]\n",
      "loss: 4.368384 [60/292]\n",
      "loss: 4.338741 [70/292]\n",
      "loss: 4.336239 [80/292]\n",
      "loss: 4.383557 [90/292]\n",
      "loss: 4.369629 [100/292]\n",
      "loss: 4.354587 [110/292]\n",
      "loss: 4.332026 [120/292]\n",
      "loss: 4.344822 [130/292]\n",
      "loss: 4.374263 [140/292]\n",
      "loss: 4.370903 [150/292]\n",
      "loss: 4.329558 [160/292]\n",
      "loss: 4.360005 [170/292]\n",
      "loss: 4.367547 [180/292]\n",
      "loss: 4.318598 [190/292]\n",
      "loss: 4.366415 [200/292]\n",
      "loss: 4.385894 [210/292]\n",
      "loss: 4.372013 [220/292]\n",
      "loss: 4.378171 [230/292]\n",
      "loss: 4.341850 [240/292]\n",
      "loss: 4.355368 [250/292]\n",
      "loss: 4.358501 [260/292]\n",
      "loss: 4.343913 [270/292]\n",
      "loss: 4.344040 [280/292]\n",
      "loss: 4.312608 [290/292]\n",
      "\n",
      "Test Accuracy: 5.9%\n",
      "Avg Loss: 4.357533\n",
      "\n",
      "Epoch 38\n",
      "-------------------------\n",
      "loss: 4.373019 [10/292]\n",
      "loss: 4.359962 [20/292]\n",
      "loss: 4.372512 [30/292]\n",
      "loss: 4.339395 [40/292]\n",
      "loss: 4.361057 [50/292]\n",
      "loss: 4.309673 [60/292]\n",
      "loss: 4.348869 [70/292]\n",
      "loss: 4.334190 [80/292]\n",
      "loss: 4.356230 [90/292]\n",
      "loss: 4.373801 [100/292]\n",
      "loss: 4.363172 [110/292]\n",
      "loss: 4.337117 [120/292]\n",
      "loss: 4.346078 [130/292]\n",
      "loss: 4.369706 [140/292]\n",
      "loss: 4.354164 [150/292]\n",
      "loss: 4.319264 [160/292]\n",
      "loss: 4.358716 [170/292]\n",
      "loss: 4.354187 [180/292]\n",
      "loss: 4.348209 [190/292]\n",
      "loss: 4.380343 [200/292]\n",
      "loss: 4.337255 [210/292]\n",
      "loss: 4.362788 [220/292]\n",
      "loss: 4.376052 [230/292]\n",
      "loss: 4.348396 [240/292]\n",
      "loss: 4.393792 [250/292]\n",
      "loss: 4.350292 [260/292]\n",
      "loss: 4.351829 [270/292]\n",
      "loss: 4.351784 [280/292]\n",
      "loss: 4.344396 [290/292]\n",
      "\n",
      "Test Accuracy: 5.9%\n",
      "Avg Loss: 4.352512\n",
      "\n",
      "Epoch 39\n",
      "-------------------------\n",
      "loss: 4.324811 [10/292]\n",
      "loss: 4.350227 [20/292]\n",
      "loss: 4.317305 [30/292]\n",
      "loss: 4.366415 [40/292]\n",
      "loss: 4.332506 [50/292]\n",
      "loss: 4.349914 [60/292]\n",
      "loss: 4.368936 [70/292]\n",
      "loss: 4.354830 [80/292]\n",
      "loss: 4.325769 [90/292]\n",
      "loss: 4.345308 [100/292]\n",
      "loss: 4.356530 [110/292]\n",
      "loss: 4.355069 [120/292]\n",
      "loss: 4.351843 [130/292]\n",
      "loss: 4.339993 [140/292]\n",
      "loss: 4.345591 [150/292]\n",
      "loss: 4.364263 [160/292]\n",
      "loss: 4.311858 [170/292]\n",
      "loss: 4.340453 [180/292]\n",
      "loss: 4.366695 [190/292]\n",
      "loss: 4.363962 [200/292]\n",
      "loss: 4.369348 [210/292]\n",
      "loss: 4.336611 [220/292]\n",
      "loss: 4.375541 [230/292]\n",
      "loss: 4.373571 [240/292]\n",
      "loss: 4.359657 [250/292]\n",
      "loss: 4.353843 [260/292]\n",
      "loss: 4.329165 [270/292]\n",
      "loss: 4.374008 [280/292]\n",
      "loss: 4.370641 [290/292]\n",
      "\n",
      "Test Accuracy: 5.9%\n",
      "Avg Loss: 4.355744\n",
      "\n",
      "Epoch 40\n",
      "-------------------------\n",
      "loss: 4.350785 [10/292]\n",
      "loss: 4.346278 [20/292]\n",
      "loss: 4.379673 [30/292]\n",
      "loss: 4.337173 [40/292]\n",
      "loss: 4.384643 [50/292]\n",
      "loss: 4.349940 [60/292]\n",
      "loss: 4.357958 [70/292]\n",
      "loss: 4.364427 [80/292]\n",
      "loss: 4.349957 [90/292]\n",
      "loss: 4.334935 [100/292]\n",
      "loss: 4.341469 [110/292]\n",
      "loss: 4.322077 [120/292]\n",
      "loss: 4.377349 [130/292]\n",
      "loss: 4.337826 [140/292]\n",
      "loss: 4.378492 [150/292]\n",
      "loss: 4.338223 [160/292]\n",
      "loss: 4.322797 [170/292]\n",
      "loss: 4.361675 [180/292]\n",
      "loss: 4.322894 [190/292]\n",
      "loss: 4.339458 [200/292]\n",
      "loss: 4.328683 [210/292]\n",
      "loss: 4.343665 [220/292]\n",
      "loss: 4.374700 [230/292]\n",
      "loss: 4.314878 [240/292]\n",
      "loss: 4.369439 [250/292]\n",
      "loss: 4.362160 [260/292]\n",
      "loss: 4.357502 [270/292]\n",
      "loss: 4.341059 [280/292]\n",
      "loss: 4.317369 [290/292]\n",
      "\n",
      "Test Accuracy: 6.0%\n",
      "Avg Loss: 4.355315\n",
      "\n",
      "Epoch 41\n",
      "-------------------------\n",
      "loss: 4.330791 [10/292]\n",
      "loss: 4.346203 [20/292]\n",
      "loss: 4.299081 [30/292]\n",
      "loss: 4.361354 [40/292]\n",
      "loss: 4.360113 [50/292]\n",
      "loss: 4.357932 [60/292]\n",
      "loss: 4.365717 [70/292]\n",
      "loss: 4.338933 [80/292]\n",
      "loss: 4.348326 [90/292]\n",
      "loss: 4.359931 [100/292]\n",
      "loss: 4.336614 [110/292]\n",
      "loss: 4.373348 [120/292]\n",
      "loss: 4.351103 [130/292]\n",
      "loss: 4.343173 [140/292]\n",
      "loss: 4.359753 [150/292]\n",
      "loss: 4.374089 [160/292]\n",
      "loss: 4.349141 [170/292]\n",
      "loss: 4.366104 [180/292]\n",
      "loss: 4.340342 [190/292]\n",
      "loss: 4.325710 [200/292]\n",
      "loss: 4.350184 [210/292]\n",
      "loss: 4.351188 [220/292]\n",
      "loss: 4.359438 [230/292]\n",
      "loss: 4.331549 [240/292]\n",
      "loss: 4.331610 [250/292]\n",
      "loss: 4.352170 [260/292]\n",
      "loss: 4.378208 [270/292]\n",
      "loss: 4.327331 [280/292]\n",
      "loss: 4.344784 [290/292]\n",
      "\n",
      "Test Accuracy: 6.3%\n",
      "Avg Loss: 4.350504\n",
      "\n",
      "Epoch 42\n",
      "-------------------------\n",
      "loss: 4.343033 [10/292]\n",
      "loss: 4.320613 [20/292]\n",
      "loss: 4.365192 [30/292]\n",
      "loss: 4.358361 [40/292]\n",
      "loss: 4.318423 [50/292]\n",
      "loss: 4.374271 [60/292]\n",
      "loss: 4.340116 [70/292]\n",
      "loss: 4.329868 [80/292]\n",
      "loss: 4.342598 [90/292]\n",
      "loss: 4.341558 [100/292]\n",
      "loss: 4.331841 [110/292]\n",
      "loss: 4.350439 [120/292]\n",
      "loss: 4.337626 [130/292]\n",
      "loss: 4.353127 [140/292]\n",
      "loss: 4.355225 [150/292]\n",
      "loss: 4.344746 [160/292]\n",
      "loss: 4.338853 [170/292]\n",
      "loss: 4.355062 [180/292]\n",
      "loss: 4.357039 [190/292]\n",
      "loss: 4.379056 [200/292]\n",
      "loss: 4.363818 [210/292]\n",
      "loss: 4.379506 [220/292]\n",
      "loss: 4.312017 [230/292]\n",
      "loss: 4.325054 [240/292]\n",
      "loss: 4.296320 [250/292]\n",
      "loss: 4.353395 [260/292]\n",
      "loss: 4.318330 [270/292]\n",
      "loss: 4.359527 [280/292]\n",
      "loss: 4.354262 [290/292]\n",
      "\n",
      "Test Accuracy: 6.7%\n",
      "Avg Loss: 4.347592\n",
      "\n",
      "Epoch 43\n",
      "-------------------------\n",
      "loss: 4.334506 [10/292]\n",
      "loss: 4.352347 [20/292]\n",
      "loss: 4.334974 [30/292]\n",
      "loss: 4.318122 [40/292]\n",
      "loss: 4.362319 [50/292]\n",
      "loss: 4.359037 [60/292]\n",
      "loss: 4.315310 [70/292]\n",
      "loss: 4.365562 [80/292]\n",
      "loss: 4.306264 [90/292]\n",
      "loss: 4.336701 [100/292]\n",
      "loss: 4.338795 [110/292]\n",
      "loss: 4.369089 [120/292]\n",
      "loss: 4.370590 [130/292]\n",
      "loss: 4.344669 [140/292]\n",
      "loss: 4.325441 [150/292]\n",
      "loss: 4.346959 [160/292]\n",
      "loss: 4.355639 [170/292]\n",
      "loss: 4.337358 [180/292]\n",
      "loss: 4.312424 [190/292]\n",
      "loss: 4.330999 [200/292]\n",
      "loss: 4.324918 [210/292]\n",
      "loss: 4.362450 [220/292]\n",
      "loss: 4.328689 [230/292]\n",
      "loss: 4.359342 [240/292]\n",
      "loss: 4.386705 [250/292]\n",
      "loss: 4.306167 [260/292]\n",
      "loss: 4.363654 [270/292]\n",
      "loss: 4.345537 [280/292]\n",
      "loss: 4.357216 [290/292]\n",
      "\n",
      "Test Accuracy: 5.9%\n",
      "Avg Loss: 4.355778\n",
      "\n",
      "Epoch 44\n",
      "-------------------------\n",
      "loss: 4.362998 [10/292]\n",
      "loss: 4.329790 [20/292]\n",
      "loss: 4.358717 [30/292]\n",
      "loss: 4.342308 [40/292]\n",
      "loss: 4.350955 [50/292]\n",
      "loss: 4.341768 [60/292]\n",
      "loss: 4.292338 [70/292]\n",
      "loss: 4.336472 [80/292]\n",
      "loss: 4.356300 [90/292]\n",
      "loss: 4.338487 [100/292]\n",
      "loss: 4.371275 [110/292]\n",
      "loss: 4.371571 [120/292]\n",
      "loss: 4.340953 [130/292]\n",
      "loss: 4.355524 [140/292]\n",
      "loss: 4.357723 [150/292]\n",
      "loss: 4.331597 [160/292]\n",
      "loss: 4.384033 [170/292]\n",
      "loss: 4.348309 [180/292]\n",
      "loss: 4.345428 [190/292]\n",
      "loss: 4.360977 [200/292]\n",
      "loss: 4.372971 [210/292]\n",
      "loss: 4.356833 [220/292]\n",
      "loss: 4.366682 [230/292]\n",
      "loss: 4.379765 [240/292]\n",
      "loss: 4.358381 [250/292]\n",
      "loss: 4.359337 [260/292]\n",
      "loss: 4.358954 [270/292]\n",
      "loss: 4.308314 [280/292]\n",
      "loss: 4.353214 [290/292]\n",
      "\n",
      "Test Accuracy: 6.5%\n",
      "Avg Loss: 4.350538\n",
      "\n",
      "Epoch 45\n",
      "-------------------------\n",
      "loss: 4.335017 [10/292]\n",
      "loss: 4.373228 [20/292]\n",
      "loss: 4.366309 [30/292]\n",
      "loss: 4.335702 [40/292]\n",
      "loss: 4.314995 [50/292]\n",
      "loss: 4.338694 [60/292]\n",
      "loss: 4.370641 [70/292]\n",
      "loss: 4.360096 [80/292]\n",
      "loss: 4.312829 [90/292]\n",
      "loss: 4.353878 [100/292]\n",
      "loss: 4.335119 [110/292]\n",
      "loss: 4.322088 [120/292]\n",
      "loss: 4.354149 [130/292]\n",
      "loss: 4.351589 [140/292]\n",
      "loss: 4.322987 [150/292]\n",
      "loss: 4.277004 [160/292]\n",
      "loss: 4.377332 [170/292]\n",
      "loss: 4.361352 [180/292]\n",
      "loss: 4.344227 [190/292]\n",
      "loss: 4.353757 [200/292]\n",
      "loss: 4.314174 [210/292]\n",
      "loss: 4.365757 [220/292]\n",
      "loss: 4.353562 [230/292]\n",
      "loss: 4.353126 [240/292]\n",
      "loss: 4.360677 [250/292]\n",
      "loss: 4.320096 [260/292]\n",
      "loss: 4.357071 [270/292]\n",
      "loss: 4.378444 [280/292]\n",
      "loss: 4.374781 [290/292]\n",
      "\n",
      "Test Accuracy: 6.5%\n",
      "Avg Loss: 4.351014\n",
      "\n",
      "Epoch 46\n",
      "-------------------------\n",
      "loss: 4.331533 [10/292]\n",
      "loss: 4.372001 [20/292]\n",
      "loss: 4.332483 [30/292]\n",
      "loss: 4.342745 [40/292]\n",
      "loss: 4.365881 [50/292]\n",
      "loss: 4.370790 [60/292]\n",
      "loss: 4.303616 [70/292]\n",
      "loss: 4.359386 [80/292]\n",
      "loss: 4.308925 [90/292]\n",
      "loss: 4.349046 [100/292]\n",
      "loss: 4.345387 [110/292]\n",
      "loss: 4.318508 [120/292]\n",
      "loss: 4.359474 [130/292]\n",
      "loss: 4.372647 [140/292]\n",
      "loss: 4.343127 [150/292]\n",
      "loss: 4.347866 [160/292]\n",
      "loss: 4.336976 [170/292]\n",
      "loss: 4.342160 [180/292]\n",
      "loss: 4.338479 [190/292]\n",
      "loss: 4.366499 [200/292]\n",
      "loss: 4.386464 [210/292]\n",
      "loss: 4.340670 [220/292]\n",
      "loss: 4.339387 [230/292]\n",
      "loss: 4.363705 [240/292]\n",
      "loss: 4.342437 [250/292]\n",
      "loss: 4.378075 [260/292]\n",
      "loss: 4.348948 [270/292]\n",
      "loss: 4.366466 [280/292]\n",
      "loss: 4.385573 [290/292]\n",
      "\n",
      "Test Accuracy: 6.2%\n",
      "Avg Loss: 4.353365\n",
      "\n",
      "Epoch 47\n",
      "-------------------------\n",
      "loss: 4.343750 [10/292]\n",
      "loss: 4.323862 [20/292]\n",
      "loss: 4.348463 [30/292]\n",
      "loss: 4.350847 [40/292]\n",
      "loss: 4.352556 [50/292]\n",
      "loss: 4.343515 [60/292]\n",
      "loss: 4.303433 [70/292]\n",
      "loss: 4.373562 [80/292]\n",
      "loss: 4.332327 [90/292]\n",
      "loss: 4.325073 [100/292]\n",
      "loss: 4.346220 [110/292]\n",
      "loss: 4.291995 [120/292]\n",
      "loss: 4.282756 [130/292]\n",
      "loss: 4.362217 [140/292]\n",
      "loss: 4.333473 [150/292]\n",
      "loss: 4.328561 [160/292]\n",
      "loss: 4.355564 [170/292]\n",
      "loss: 4.344083 [180/292]\n",
      "loss: 4.358511 [190/292]\n",
      "loss: 4.344862 [200/292]\n",
      "loss: 4.326602 [210/292]\n",
      "loss: 4.373795 [220/292]\n",
      "loss: 4.304623 [230/292]\n",
      "loss: 4.325570 [240/292]\n",
      "loss: 4.370759 [250/292]\n",
      "loss: 4.337995 [260/292]\n",
      "loss: 4.362316 [270/292]\n",
      "loss: 4.330861 [280/292]\n",
      "loss: 4.291861 [290/292]\n",
      "\n",
      "Test Accuracy: 6.7%\n",
      "Avg Loss: 4.346651\n",
      "\n",
      "Epoch 48\n",
      "-------------------------\n",
      "loss: 4.382943 [10/292]\n",
      "loss: 4.356210 [20/292]\n",
      "loss: 4.331402 [30/292]\n",
      "loss: 4.351723 [40/292]\n",
      "loss: 4.343721 [50/292]\n",
      "loss: 4.338541 [60/292]\n",
      "loss: 4.308875 [70/292]\n",
      "loss: 4.321769 [80/292]\n",
      "loss: 4.357595 [90/292]\n",
      "loss: 4.350767 [100/292]\n",
      "loss: 4.363873 [110/292]\n",
      "loss: 4.348772 [120/292]\n",
      "loss: 4.324432 [130/292]\n",
      "loss: 4.340506 [140/292]\n",
      "loss: 4.349929 [150/292]\n",
      "loss: 4.332632 [160/292]\n",
      "loss: 4.329084 [170/292]\n",
      "loss: 4.353842 [180/292]\n",
      "loss: 4.322839 [190/292]\n",
      "loss: 4.358970 [200/292]\n",
      "loss: 4.330743 [210/292]\n",
      "loss: 4.340953 [220/292]\n",
      "loss: 4.353375 [230/292]\n",
      "loss: 4.325912 [240/292]\n",
      "loss: 4.321235 [250/292]\n",
      "loss: 4.364317 [260/292]\n",
      "loss: 4.321290 [270/292]\n",
      "loss: 4.372534 [280/292]\n",
      "loss: 4.317347 [290/292]\n",
      "\n",
      "Test Accuracy: 6.6%\n",
      "Avg Loss: 4.347577\n",
      "\n",
      "Epoch 49\n",
      "-------------------------\n",
      "loss: 4.345834 [10/292]\n",
      "loss: 4.352020 [20/292]\n",
      "loss: 4.339122 [30/292]\n",
      "loss: 4.353548 [40/292]\n",
      "loss: 4.345763 [50/292]\n",
      "loss: 4.306680 [60/292]\n",
      "loss: 4.338084 [70/292]\n",
      "loss: 4.363949 [80/292]\n",
      "loss: 4.355200 [90/292]\n",
      "loss: 4.310374 [100/292]\n",
      "loss: 4.333444 [110/292]\n",
      "loss: 4.341352 [120/292]\n",
      "loss: 4.317791 [130/292]\n",
      "loss: 4.304078 [140/292]\n",
      "loss: 4.326065 [150/292]\n",
      "loss: 4.335378 [160/292]\n",
      "loss: 4.381394 [170/292]\n",
      "loss: 4.357157 [180/292]\n",
      "loss: 4.349363 [190/292]\n",
      "loss: 4.348042 [200/292]\n",
      "loss: 4.353794 [210/292]\n",
      "loss: 4.364969 [220/292]\n",
      "loss: 4.341410 [230/292]\n",
      "loss: 4.360521 [240/292]\n",
      "loss: 4.352242 [250/292]\n",
      "loss: 4.361394 [260/292]\n",
      "loss: 4.312464 [270/292]\n",
      "loss: 4.375432 [280/292]\n",
      "loss: 4.351649 [290/292]\n",
      "\n",
      "Test Accuracy: 6.8%\n",
      "Avg Loss: 4.346594\n",
      "\n",
      "Epoch 50\n",
      "-------------------------\n",
      "loss: 4.344139 [10/292]\n",
      "loss: 4.344679 [20/292]\n",
      "loss: 4.352659 [30/292]\n",
      "loss: 4.341906 [40/292]\n",
      "loss: 4.325311 [50/292]\n",
      "loss: 4.351974 [60/292]\n",
      "loss: 4.353661 [70/292]\n",
      "loss: 4.331616 [80/292]\n",
      "loss: 4.332381 [90/292]\n",
      "loss: 4.340218 [100/292]\n",
      "loss: 4.354205 [110/292]\n",
      "loss: 4.336711 [120/292]\n",
      "loss: 4.339354 [130/292]\n",
      "loss: 4.305032 [140/292]\n",
      "loss: 4.353470 [150/292]\n",
      "loss: 4.360516 [160/292]\n",
      "loss: 4.381346 [170/292]\n",
      "loss: 4.315374 [180/292]\n",
      "loss: 4.313297 [190/292]\n",
      "loss: 4.354797 [200/292]\n",
      "loss: 4.336970 [210/292]\n",
      "loss: 4.347594 [220/292]\n",
      "loss: 4.351854 [230/292]\n",
      "loss: 4.335884 [240/292]\n",
      "loss: 4.324860 [250/292]\n",
      "loss: 4.340210 [260/292]\n",
      "loss: 4.320229 [270/292]\n",
      "loss: 4.393533 [280/292]\n",
      "loss: 4.352509 [290/292]\n",
      "\n",
      "Test Accuracy: 6.6%\n",
      "Avg Loss: 4.348421\n",
      "\n",
      "Epoch 51\n",
      "-------------------------\n",
      "loss: 4.350102 [10/292]\n",
      "loss: 4.349726 [20/292]\n",
      "loss: 4.313072 [30/292]\n",
      "loss: 4.338396 [40/292]\n",
      "loss: 4.362417 [50/292]\n",
      "loss: 4.336360 [60/292]\n",
      "loss: 4.356796 [70/292]\n",
      "loss: 4.319726 [80/292]\n",
      "loss: 4.344126 [90/292]\n",
      "loss: 4.325853 [100/292]\n",
      "loss: 4.346359 [110/292]\n",
      "loss: 4.363623 [120/292]\n",
      "loss: 4.317708 [130/292]\n",
      "loss: 4.313760 [140/292]\n",
      "loss: 4.338321 [150/292]\n",
      "loss: 4.344018 [160/292]\n",
      "loss: 4.349700 [170/292]\n",
      "loss: 4.328351 [180/292]\n",
      "loss: 4.364103 [190/292]\n",
      "loss: 4.321660 [200/292]\n",
      "loss: 4.319079 [210/292]\n",
      "loss: 4.349357 [220/292]\n",
      "loss: 4.339375 [230/292]\n",
      "loss: 4.310939 [240/292]\n",
      "loss: 4.317388 [250/292]\n",
      "loss: 4.329322 [260/292]\n",
      "loss: 4.281073 [270/292]\n",
      "loss: 4.326256 [280/292]\n",
      "loss: 4.361114 [290/292]\n",
      "\n",
      "Test Accuracy: 6.7%\n",
      "Avg Loss: 4.347848\n",
      "\n",
      "Epoch 52\n",
      "-------------------------\n",
      "loss: 4.369968 [10/292]\n",
      "loss: 4.350356 [20/292]\n",
      "loss: 4.339919 [30/292]\n",
      "loss: 4.292585 [40/292]\n",
      "loss: 4.356028 [50/292]\n",
      "loss: 4.348586 [60/292]\n",
      "loss: 4.364946 [70/292]\n",
      "loss: 4.358533 [80/292]\n",
      "loss: 4.347083 [90/292]\n",
      "loss: 4.343544 [100/292]\n",
      "loss: 4.351627 [110/292]\n",
      "loss: 4.377073 [120/292]\n",
      "loss: 4.344349 [130/292]\n",
      "loss: 4.336194 [140/292]\n",
      "loss: 4.340497 [150/292]\n",
      "loss: 4.334514 [160/292]\n",
      "loss: 4.383188 [170/292]\n",
      "loss: 4.349753 [180/292]\n",
      "loss: 4.326853 [190/292]\n",
      "loss: 4.349869 [200/292]\n",
      "loss: 4.364799 [210/292]\n",
      "loss: 4.335037 [220/292]\n",
      "loss: 4.339042 [230/292]\n",
      "loss: 4.354838 [240/292]\n",
      "loss: 4.353969 [250/292]\n",
      "loss: 4.322605 [260/292]\n",
      "loss: 4.306538 [270/292]\n",
      "loss: 4.322875 [280/292]\n",
      "loss: 4.365441 [290/292]\n",
      "\n",
      "Test Accuracy: 7.0%\n",
      "Avg Loss: 4.344929\n",
      "\n",
      "Epoch 53\n",
      "-------------------------\n",
      "loss: 4.360581 [10/292]\n",
      "loss: 4.343029 [20/292]\n",
      "loss: 4.344606 [30/292]\n",
      "loss: 4.322261 [40/292]\n",
      "loss: 4.340170 [50/292]\n",
      "loss: 4.332703 [60/292]\n",
      "loss: 4.324460 [70/292]\n",
      "loss: 4.358995 [80/292]\n",
      "loss: 4.246798 [90/292]\n",
      "loss: 4.327470 [100/292]\n",
      "loss: 4.351897 [110/292]\n",
      "loss: 4.344959 [120/292]\n",
      "loss: 4.367442 [130/292]\n",
      "loss: 4.336123 [140/292]\n",
      "loss: 4.363791 [150/292]\n",
      "loss: 4.328867 [160/292]\n",
      "loss: 4.357267 [170/292]\n",
      "loss: 4.313656 [180/292]\n",
      "loss: 4.337585 [190/292]\n",
      "loss: 4.388862 [200/292]\n",
      "loss: 4.347078 [210/292]\n",
      "loss: 4.350657 [220/292]\n",
      "loss: 4.335485 [230/292]\n",
      "loss: 4.348481 [240/292]\n",
      "loss: 4.349371 [250/292]\n",
      "loss: 4.372395 [260/292]\n",
      "loss: 4.306825 [270/292]\n",
      "loss: 4.326888 [280/292]\n",
      "loss: 4.350430 [290/292]\n",
      "\n",
      "Test Accuracy: 7.2%\n",
      "Avg Loss: 4.343053\n",
      "\n",
      "Epoch 54\n",
      "-------------------------\n",
      "loss: 4.355004 [10/292]\n",
      "loss: 4.296285 [20/292]\n",
      "loss: 4.367043 [30/292]\n",
      "loss: 4.331941 [40/292]\n",
      "loss: 4.320821 [50/292]\n",
      "loss: 4.281904 [60/292]\n",
      "loss: 4.316894 [70/292]\n",
      "loss: 4.355132 [80/292]\n",
      "loss: 4.318500 [90/292]\n",
      "loss: 4.336893 [100/292]\n",
      "loss: 4.319142 [110/292]\n",
      "loss: 4.348954 [120/292]\n",
      "loss: 4.332330 [130/292]\n",
      "loss: 4.335072 [140/292]\n",
      "loss: 4.382677 [150/292]\n",
      "loss: 4.313942 [160/292]\n",
      "loss: 4.340779 [170/292]\n",
      "loss: 4.315068 [180/292]\n",
      "loss: 4.337264 [190/292]\n",
      "loss: 4.311732 [200/292]\n",
      "loss: 4.332671 [210/292]\n",
      "loss: 4.327168 [220/292]\n",
      "loss: 4.306230 [230/292]\n",
      "loss: 4.331934 [240/292]\n",
      "loss: 4.378993 [250/292]\n",
      "loss: 4.359421 [260/292]\n",
      "loss: 4.384869 [270/292]\n",
      "loss: 4.322939 [280/292]\n",
      "loss: 4.361415 [290/292]\n",
      "\n",
      "Test Accuracy: 6.9%\n",
      "Avg Loss: 4.345822\n",
      "\n",
      "Epoch 55\n",
      "-------------------------\n",
      "loss: 4.348413 [10/292]\n",
      "loss: 4.302558 [20/292]\n",
      "loss: 4.292951 [30/292]\n",
      "loss: 4.322379 [40/292]\n",
      "loss: 4.366948 [50/292]\n",
      "loss: 4.348233 [60/292]\n",
      "loss: 4.348122 [70/292]\n",
      "loss: 4.361728 [80/292]\n",
      "loss: 4.371355 [90/292]\n",
      "loss: 4.329930 [100/292]\n",
      "loss: 4.324581 [110/292]\n",
      "loss: 4.353633 [120/292]\n",
      "loss: 4.348568 [130/292]\n",
      "loss: 4.374053 [140/292]\n",
      "loss: 4.339341 [150/292]\n",
      "loss: 4.332202 [160/292]\n",
      "loss: 4.353730 [170/292]\n",
      "loss: 4.354792 [180/292]\n",
      "loss: 4.329061 [190/292]\n",
      "loss: 4.354924 [200/292]\n",
      "loss: 4.331022 [210/292]\n",
      "loss: 4.338559 [220/292]\n",
      "loss: 4.344635 [230/292]\n",
      "loss: 4.305028 [240/292]\n",
      "loss: 4.318987 [250/292]\n",
      "loss: 4.289503 [260/292]\n",
      "loss: 4.367908 [270/292]\n",
      "loss: 4.347993 [280/292]\n",
      "loss: 4.350348 [290/292]\n",
      "\n",
      "Test Accuracy: 7.4%\n",
      "Avg Loss: 4.341490\n",
      "\n",
      "Epoch 56\n",
      "-------------------------\n",
      "loss: 4.361029 [10/292]\n",
      "loss: 4.342666 [20/292]\n",
      "loss: 4.366365 [30/292]\n",
      "loss: 4.355583 [40/292]\n",
      "loss: 4.325864 [50/292]\n",
      "loss: 4.302004 [60/292]\n",
      "loss: 4.313745 [70/292]\n",
      "loss: 4.343119 [80/292]\n",
      "loss: 4.350667 [90/292]\n",
      "loss: 4.301555 [100/292]\n",
      "loss: 4.315972 [110/292]\n",
      "loss: 4.369248 [120/292]\n",
      "loss: 4.340915 [130/292]\n",
      "loss: 4.353588 [140/292]\n",
      "loss: 4.379918 [150/292]\n",
      "loss: 4.347238 [160/292]\n",
      "loss: 4.309660 [170/292]\n",
      "loss: 4.349804 [180/292]\n",
      "loss: 4.342510 [190/292]\n",
      "loss: 4.374273 [200/292]\n",
      "loss: 4.320434 [210/292]\n",
      "loss: 4.328012 [220/292]\n",
      "loss: 4.348527 [230/292]\n",
      "loss: 4.335111 [240/292]\n",
      "loss: 4.314780 [250/292]\n",
      "loss: 4.367130 [260/292]\n",
      "loss: 4.391705 [270/292]\n",
      "loss: 4.309882 [280/292]\n",
      "loss: 4.356243 [290/292]\n",
      "\n",
      "Test Accuracy: 7.1%\n",
      "Avg Loss: 4.344129\n",
      "\n",
      "Epoch 57\n",
      "-------------------------\n",
      "loss: 4.350598 [10/292]\n",
      "loss: 4.338047 [20/292]\n",
      "loss: 4.350586 [30/292]\n",
      "loss: 4.329308 [40/292]\n",
      "loss: 4.304900 [50/292]\n",
      "loss: 4.351518 [60/292]\n",
      "loss: 4.339764 [70/292]\n",
      "loss: 4.363787 [80/292]\n",
      "loss: 4.296960 [90/292]\n",
      "loss: 4.331653 [100/292]\n",
      "loss: 4.313807 [110/292]\n",
      "loss: 4.341774 [120/292]\n",
      "loss: 4.347191 [130/292]\n",
      "loss: 4.334415 [140/292]\n",
      "loss: 4.349180 [150/292]\n",
      "loss: 4.354760 [160/292]\n",
      "loss: 4.355612 [170/292]\n",
      "loss: 4.344862 [180/292]\n",
      "loss: 4.344106 [190/292]\n",
      "loss: 4.354942 [200/292]\n",
      "loss: 4.318948 [210/292]\n",
      "loss: 4.335380 [220/292]\n",
      "loss: 4.336627 [230/292]\n",
      "loss: 4.336219 [240/292]\n",
      "loss: 4.326874 [250/292]\n",
      "loss: 4.302145 [260/292]\n",
      "loss: 4.372674 [270/292]\n",
      "loss: 4.329865 [280/292]\n",
      "loss: 4.373456 [290/292]\n",
      "\n",
      "Test Accuracy: 7.3%\n",
      "Avg Loss: 4.343520\n",
      "\n",
      "Epoch 58\n",
      "-------------------------\n",
      "loss: 4.350458 [10/292]\n",
      "loss: 4.300263 [20/292]\n",
      "loss: 4.349657 [30/292]\n",
      "loss: 4.295788 [40/292]\n",
      "loss: 4.309454 [50/292]\n",
      "loss: 4.337417 [60/292]\n",
      "loss: 4.350024 [70/292]\n",
      "loss: 4.374133 [80/292]\n",
      "loss: 4.371965 [90/292]\n",
      "loss: 4.316969 [100/292]\n",
      "loss: 4.294134 [110/292]\n",
      "loss: 4.316871 [120/292]\n",
      "loss: 4.340703 [130/292]\n",
      "loss: 4.331836 [140/292]\n",
      "loss: 4.328074 [150/292]\n",
      "loss: 4.322371 [160/292]\n",
      "loss: 4.338120 [170/292]\n",
      "loss: 4.333470 [180/292]\n",
      "loss: 4.337794 [190/292]\n",
      "loss: 4.351431 [200/292]\n",
      "loss: 4.363027 [210/292]\n",
      "loss: 4.364746 [220/292]\n",
      "loss: 4.364599 [230/292]\n",
      "loss: 4.331645 [240/292]\n",
      "loss: 4.363501 [250/292]\n",
      "loss: 4.300198 [260/292]\n",
      "loss: 4.367448 [270/292]\n",
      "loss: 4.336979 [280/292]\n",
      "loss: 4.336861 [290/292]\n",
      "\n",
      "Test Accuracy: 6.9%\n",
      "Avg Loss: 4.345183\n",
      "\n",
      "Epoch 59\n",
      "-------------------------\n",
      "loss: 4.356568 [10/292]\n",
      "loss: 4.373191 [20/292]\n",
      "loss: 4.280296 [30/292]\n",
      "loss: 4.301896 [40/292]\n",
      "loss: 4.342062 [50/292]\n",
      "loss: 4.359771 [60/292]\n",
      "loss: 4.294273 [70/292]\n",
      "loss: 4.325299 [80/292]\n",
      "loss: 4.341002 [90/292]\n",
      "loss: 4.357500 [100/292]\n",
      "loss: 4.372235 [110/292]\n",
      "loss: 4.322548 [120/292]\n",
      "loss: 4.346047 [130/292]\n",
      "loss: 4.351163 [140/292]\n",
      "loss: 4.284734 [150/292]\n",
      "loss: 4.331897 [160/292]\n",
      "loss: 4.328679 [170/292]\n",
      "loss: 4.366466 [180/292]\n",
      "loss: 4.345923 [190/292]\n",
      "loss: 4.347126 [200/292]\n",
      "loss: 4.320495 [210/292]\n",
      "loss: 4.336648 [220/292]\n",
      "loss: 4.366294 [230/292]\n",
      "loss: 4.326832 [240/292]\n",
      "loss: 4.340689 [250/292]\n",
      "loss: 4.373372 [260/292]\n",
      "loss: 4.350784 [270/292]\n",
      "loss: 4.339556 [280/292]\n",
      "loss: 4.344339 [290/292]\n",
      "\n",
      "Test Accuracy: 7.8%\n",
      "Avg Loss: 4.337671\n",
      "\n",
      "Epoch 60\n",
      "-------------------------\n",
      "loss: 4.310853 [10/292]\n",
      "loss: 4.318661 [20/292]\n",
      "loss: 4.314014 [30/292]\n",
      "loss: 4.378149 [40/292]\n",
      "loss: 4.385394 [50/292]\n",
      "loss: 4.343091 [60/292]\n",
      "loss: 4.324765 [70/292]\n",
      "loss: 4.326131 [80/292]\n",
      "loss: 4.349537 [90/292]\n",
      "loss: 4.369167 [100/292]\n",
      "loss: 4.327424 [110/292]\n",
      "loss: 4.364593 [120/292]\n",
      "loss: 4.326634 [130/292]\n",
      "loss: 4.353028 [140/292]\n",
      "loss: 4.366640 [150/292]\n",
      "loss: 4.346609 [160/292]\n",
      "loss: 4.338772 [170/292]\n",
      "loss: 4.375715 [180/292]\n",
      "loss: 4.279938 [190/292]\n",
      "loss: 4.330346 [200/292]\n",
      "loss: 4.330304 [210/292]\n",
      "loss: 4.318338 [220/292]\n",
      "loss: 4.369394 [230/292]\n",
      "loss: 4.332004 [240/292]\n",
      "loss: 4.349272 [250/292]\n",
      "loss: 4.325351 [260/292]\n",
      "loss: 4.343514 [270/292]\n",
      "loss: 4.327771 [280/292]\n",
      "loss: 4.327792 [290/292]\n",
      "\n",
      "Test Accuracy: 8.1%\n",
      "Avg Loss: 4.335991\n",
      "\n",
      "Epoch 61\n",
      "-------------------------\n",
      "loss: 4.346385 [10/292]\n",
      "loss: 4.336637 [20/292]\n",
      "loss: 4.322047 [30/292]\n",
      "loss: 4.367115 [40/292]\n",
      "loss: 4.316066 [50/292]\n",
      "loss: 4.319316 [60/292]\n",
      "loss: 4.323381 [70/292]\n",
      "loss: 4.290040 [80/292]\n",
      "loss: 4.316499 [90/292]\n",
      "loss: 4.359178 [100/292]\n",
      "loss: 4.293537 [110/292]\n",
      "loss: 4.356454 [120/292]\n",
      "loss: 4.351183 [130/292]\n",
      "loss: 4.398582 [140/292]\n",
      "loss: 4.368154 [150/292]\n",
      "loss: 4.354246 [160/292]\n",
      "loss: 4.357397 [170/292]\n",
      "loss: 4.288703 [180/292]\n",
      "loss: 4.315255 [190/292]\n",
      "loss: 4.329701 [200/292]\n",
      "loss: 4.344360 [210/292]\n",
      "loss: 4.347115 [220/292]\n",
      "loss: 4.338414 [230/292]\n",
      "loss: 4.356843 [240/292]\n",
      "loss: 4.330107 [250/292]\n",
      "loss: 4.313193 [260/292]\n",
      "loss: 4.319854 [270/292]\n",
      "loss: 4.319607 [280/292]\n",
      "loss: 4.338139 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.341353\n",
      "\n",
      "Epoch 62\n",
      "-------------------------\n",
      "loss: 4.324105 [10/292]\n",
      "loss: 4.326359 [20/292]\n",
      "loss: 4.338346 [30/292]\n",
      "loss: 4.311170 [40/292]\n",
      "loss: 4.329530 [50/292]\n",
      "loss: 4.339001 [60/292]\n",
      "loss: 4.374660 [70/292]\n",
      "loss: 4.345826 [80/292]\n",
      "loss: 4.369695 [90/292]\n",
      "loss: 4.349496 [100/292]\n",
      "loss: 4.319221 [110/292]\n",
      "loss: 4.308681 [120/292]\n",
      "loss: 4.351831 [130/292]\n",
      "loss: 4.363687 [140/292]\n",
      "loss: 4.344207 [150/292]\n",
      "loss: 4.357858 [160/292]\n",
      "loss: 4.360502 [170/292]\n",
      "loss: 4.344111 [180/292]\n",
      "loss: 4.334070 [190/292]\n",
      "loss: 4.341598 [200/292]\n",
      "loss: 4.307813 [210/292]\n",
      "loss: 4.315937 [220/292]\n",
      "loss: 4.303064 [230/292]\n",
      "loss: 4.374944 [240/292]\n",
      "loss: 4.335850 [250/292]\n",
      "loss: 4.384877 [260/292]\n",
      "loss: 4.358023 [270/292]\n",
      "loss: 4.328936 [280/292]\n",
      "loss: 4.316901 [290/292]\n",
      "\n",
      "Test Accuracy: 7.1%\n",
      "Avg Loss: 4.343363\n",
      "\n",
      "Epoch 63\n",
      "-------------------------\n",
      "loss: 4.346766 [10/292]\n",
      "loss: 4.338649 [20/292]\n",
      "loss: 4.340801 [30/292]\n",
      "loss: 4.329150 [40/292]\n",
      "loss: 4.391309 [50/292]\n",
      "loss: 4.365504 [60/292]\n",
      "loss: 4.325835 [70/292]\n",
      "loss: 4.324084 [80/292]\n",
      "loss: 4.346549 [90/292]\n",
      "loss: 4.347997 [100/292]\n",
      "loss: 4.310058 [110/292]\n",
      "loss: 4.332786 [120/292]\n",
      "loss: 4.338482 [130/292]\n",
      "loss: 4.338555 [140/292]\n",
      "loss: 4.344987 [150/292]\n",
      "loss: 4.348716 [160/292]\n",
      "loss: 4.334656 [170/292]\n",
      "loss: 4.374966 [180/292]\n",
      "loss: 4.352811 [190/292]\n",
      "loss: 4.319704 [200/292]\n",
      "loss: 4.318588 [210/292]\n",
      "loss: 4.323993 [220/292]\n",
      "loss: 4.354411 [230/292]\n",
      "loss: 4.330652 [240/292]\n",
      "loss: 4.336749 [250/292]\n",
      "loss: 4.330481 [260/292]\n",
      "loss: 4.335060 [270/292]\n",
      "loss: 4.307423 [280/292]\n",
      "loss: 4.321239 [290/292]\n",
      "\n",
      "Test Accuracy: 7.4%\n",
      "Avg Loss: 4.341116\n",
      "\n",
      "Epoch 64\n",
      "-------------------------\n",
      "loss: 4.325280 [10/292]\n",
      "loss: 4.289696 [20/292]\n",
      "loss: 4.326856 [30/292]\n",
      "loss: 4.349337 [40/292]\n",
      "loss: 4.363446 [50/292]\n",
      "loss: 4.320259 [60/292]\n",
      "loss: 4.356258 [70/292]\n",
      "loss: 4.323899 [80/292]\n",
      "loss: 4.354013 [90/292]\n",
      "loss: 4.345567 [100/292]\n",
      "loss: 4.330822 [110/292]\n",
      "loss: 4.327082 [120/292]\n",
      "loss: 4.367695 [130/292]\n",
      "loss: 4.329316 [140/292]\n",
      "loss: 4.382773 [150/292]\n",
      "loss: 4.341897 [160/292]\n",
      "loss: 4.352575 [170/292]\n",
      "loss: 4.335612 [180/292]\n",
      "loss: 4.339909 [190/292]\n",
      "loss: 4.339460 [200/292]\n",
      "loss: 4.376614 [210/292]\n",
      "loss: 4.339211 [220/292]\n",
      "loss: 4.323247 [230/292]\n",
      "loss: 4.322469 [240/292]\n",
      "loss: 4.314554 [250/292]\n",
      "loss: 4.362662 [260/292]\n",
      "loss: 4.301874 [270/292]\n",
      "loss: 4.358022 [280/292]\n",
      "loss: 4.351755 [290/292]\n",
      "\n",
      "Test Accuracy: 6.9%\n",
      "Avg Loss: 4.344870\n",
      "\n",
      "Epoch 65\n",
      "-------------------------\n",
      "loss: 4.355936 [10/292]\n",
      "loss: 4.350025 [20/292]\n",
      "loss: 4.335220 [30/292]\n",
      "loss: 4.311671 [40/292]\n",
      "loss: 4.337901 [50/292]\n",
      "loss: 4.311161 [60/292]\n",
      "loss: 4.355543 [70/292]\n",
      "loss: 4.347506 [80/292]\n",
      "loss: 4.315112 [90/292]\n",
      "loss: 4.346125 [100/292]\n",
      "loss: 4.327533 [110/292]\n",
      "loss: 4.324959 [120/292]\n",
      "loss: 4.351833 [130/292]\n",
      "loss: 4.366059 [140/292]\n",
      "loss: 4.340988 [150/292]\n",
      "loss: 4.327667 [160/292]\n",
      "loss: 4.327943 [170/292]\n",
      "loss: 4.312641 [180/292]\n",
      "loss: 4.328411 [190/292]\n",
      "loss: 4.330728 [200/292]\n",
      "loss: 4.320495 [210/292]\n",
      "loss: 4.351757 [220/292]\n",
      "loss: 4.364269 [230/292]\n",
      "loss: 4.313848 [240/292]\n",
      "loss: 4.338428 [250/292]\n",
      "loss: 4.292743 [260/292]\n",
      "loss: 4.334724 [270/292]\n",
      "loss: 4.303117 [280/292]\n",
      "loss: 4.330002 [290/292]\n",
      "\n",
      "Test Accuracy: 7.3%\n",
      "Avg Loss: 4.342943\n",
      "\n",
      "Epoch 66\n",
      "-------------------------\n",
      "loss: 4.348591 [10/292]\n",
      "loss: 4.279616 [20/292]\n",
      "loss: 4.314121 [30/292]\n",
      "loss: 4.346385 [40/292]\n",
      "loss: 4.296242 [50/292]\n",
      "loss: 4.327389 [60/292]\n",
      "loss: 4.341523 [70/292]\n",
      "loss: 4.302424 [80/292]\n",
      "loss: 4.362788 [90/292]\n",
      "loss: 4.318677 [100/292]\n",
      "loss: 4.334635 [110/292]\n",
      "loss: 4.329654 [120/292]\n",
      "loss: 4.340783 [130/292]\n",
      "loss: 4.348887 [140/292]\n",
      "loss: 4.360800 [150/292]\n",
      "loss: 4.360454 [160/292]\n",
      "loss: 4.312062 [170/292]\n",
      "loss: 4.267750 [180/292]\n",
      "loss: 4.307565 [190/292]\n",
      "loss: 4.335342 [200/292]\n",
      "loss: 4.270975 [210/292]\n",
      "loss: 4.367444 [220/292]\n",
      "loss: 4.340090 [230/292]\n",
      "loss: 4.339042 [240/292]\n",
      "loss: 4.338731 [250/292]\n",
      "loss: 4.346821 [260/292]\n",
      "loss: 4.330107 [270/292]\n",
      "loss: 4.342553 [280/292]\n",
      "loss: 4.351685 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.340587\n",
      "\n",
      "Epoch 67\n",
      "-------------------------\n",
      "loss: 4.309341 [10/292]\n",
      "loss: 4.357059 [20/292]\n",
      "loss: 4.322563 [30/292]\n",
      "loss: 4.370305 [40/292]\n",
      "loss: 4.348775 [50/292]\n",
      "loss: 4.379478 [60/292]\n",
      "loss: 4.297723 [70/292]\n",
      "loss: 4.364004 [80/292]\n",
      "loss: 4.378827 [90/292]\n",
      "loss: 4.365993 [100/292]\n",
      "loss: 4.355006 [110/292]\n",
      "loss: 4.325233 [120/292]\n",
      "loss: 4.315911 [130/292]\n",
      "loss: 4.298822 [140/292]\n",
      "loss: 4.300548 [150/292]\n",
      "loss: 4.367045 [160/292]\n",
      "loss: 4.308411 [170/292]\n",
      "loss: 4.319028 [180/292]\n",
      "loss: 4.401473 [190/292]\n",
      "loss: 4.349681 [200/292]\n",
      "loss: 4.353685 [210/292]\n",
      "loss: 4.331901 [220/292]\n",
      "loss: 4.349702 [230/292]\n",
      "loss: 4.380497 [240/292]\n",
      "loss: 4.330245 [250/292]\n",
      "loss: 4.338297 [260/292]\n",
      "loss: 4.300131 [270/292]\n",
      "loss: 4.335124 [280/292]\n",
      "loss: 4.329236 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.339457\n",
      "\n",
      "Epoch 68\n",
      "-------------------------\n",
      "loss: 4.362448 [10/292]\n",
      "loss: 4.355902 [20/292]\n",
      "loss: 4.320179 [30/292]\n",
      "loss: 4.366079 [40/292]\n",
      "loss: 4.320571 [50/292]\n",
      "loss: 4.363023 [60/292]\n",
      "loss: 4.331664 [70/292]\n",
      "loss: 4.367403 [80/292]\n",
      "loss: 4.362029 [90/292]\n",
      "loss: 4.346871 [100/292]\n",
      "loss: 4.322687 [110/292]\n",
      "loss: 4.350561 [120/292]\n",
      "loss: 4.350886 [130/292]\n",
      "loss: 4.311735 [140/292]\n",
      "loss: 4.325036 [150/292]\n",
      "loss: 4.362239 [160/292]\n",
      "loss: 4.360618 [170/292]\n",
      "loss: 4.332589 [180/292]\n",
      "loss: 4.328147 [190/292]\n",
      "loss: 4.335184 [200/292]\n",
      "loss: 4.358908 [210/292]\n",
      "loss: 4.330200 [220/292]\n",
      "loss: 4.331526 [230/292]\n",
      "loss: 4.341216 [240/292]\n",
      "loss: 4.354736 [250/292]\n",
      "loss: 4.323447 [260/292]\n",
      "loss: 4.294475 [270/292]\n",
      "loss: 4.292812 [280/292]\n",
      "loss: 4.356302 [290/292]\n",
      "\n",
      "Test Accuracy: 7.6%\n",
      "Avg Loss: 4.339339\n",
      "\n",
      "Epoch 69\n",
      "-------------------------\n",
      "loss: 4.300561 [10/292]\n",
      "loss: 4.347601 [20/292]\n",
      "loss: 4.320595 [30/292]\n",
      "loss: 4.304050 [40/292]\n",
      "loss: 4.295803 [50/292]\n",
      "loss: 4.342726 [60/292]\n",
      "loss: 4.350708 [70/292]\n",
      "loss: 4.323953 [80/292]\n",
      "loss: 4.320534 [90/292]\n",
      "loss: 4.291413 [100/292]\n",
      "loss: 4.327101 [110/292]\n",
      "loss: 4.319785 [120/292]\n",
      "loss: 4.324380 [130/292]\n",
      "loss: 4.327994 [140/292]\n",
      "loss: 4.360824 [150/292]\n",
      "loss: 4.318208 [160/292]\n",
      "loss: 4.332796 [170/292]\n",
      "loss: 4.292799 [180/292]\n",
      "loss: 4.339901 [190/292]\n",
      "loss: 4.324378 [200/292]\n",
      "loss: 4.346747 [210/292]\n",
      "loss: 4.315851 [220/292]\n",
      "loss: 4.294253 [230/292]\n",
      "loss: 4.396286 [240/292]\n",
      "loss: 4.313396 [250/292]\n",
      "loss: 4.339989 [260/292]\n",
      "loss: 4.352837 [270/292]\n",
      "loss: 4.335566 [280/292]\n",
      "loss: 4.324088 [290/292]\n",
      "\n",
      "Test Accuracy: 6.8%\n",
      "Avg Loss: 4.346445\n",
      "\n",
      "Epoch 70\n",
      "-------------------------\n",
      "loss: 4.341148 [10/292]\n",
      "loss: 4.355003 [20/292]\n",
      "loss: 4.338461 [30/292]\n",
      "loss: 4.347689 [40/292]\n",
      "loss: 4.334549 [50/292]\n",
      "loss: 4.341740 [60/292]\n",
      "loss: 4.302505 [70/292]\n",
      "loss: 4.366712 [80/292]\n",
      "loss: 4.315834 [90/292]\n",
      "loss: 4.310456 [100/292]\n",
      "loss: 4.321455 [110/292]\n",
      "loss: 4.345154 [120/292]\n",
      "loss: 4.349458 [130/292]\n",
      "loss: 4.287426 [140/292]\n",
      "loss: 4.311946 [150/292]\n",
      "loss: 4.297035 [160/292]\n",
      "loss: 4.310431 [170/292]\n",
      "loss: 4.344273 [180/292]\n",
      "loss: 4.349020 [190/292]\n",
      "loss: 4.369742 [200/292]\n",
      "loss: 4.301416 [210/292]\n",
      "loss: 4.353483 [220/292]\n",
      "loss: 4.312693 [230/292]\n",
      "loss: 4.295505 [240/292]\n",
      "loss: 4.312090 [250/292]\n",
      "loss: 4.349125 [260/292]\n",
      "loss: 4.332123 [270/292]\n",
      "loss: 4.297718 [280/292]\n",
      "loss: 4.307542 [290/292]\n",
      "\n",
      "Test Accuracy: 7.3%\n",
      "Avg Loss: 4.341574\n",
      "\n",
      "Epoch 71\n",
      "-------------------------\n",
      "loss: 4.347668 [10/292]\n",
      "loss: 4.313099 [20/292]\n",
      "loss: 4.351945 [30/292]\n",
      "loss: 4.350677 [40/292]\n",
      "loss: 4.305521 [50/292]\n",
      "loss: 4.348999 [60/292]\n",
      "loss: 4.331522 [70/292]\n",
      "loss: 4.326611 [80/292]\n",
      "loss: 4.339044 [90/292]\n",
      "loss: 4.312269 [100/292]\n",
      "loss: 4.334807 [110/292]\n",
      "loss: 4.348745 [120/292]\n",
      "loss: 4.366453 [130/292]\n",
      "loss: 4.290418 [140/292]\n",
      "loss: 4.353060 [150/292]\n",
      "loss: 4.350208 [160/292]\n",
      "loss: 4.343043 [170/292]\n",
      "loss: 4.346428 [180/292]\n",
      "loss: 4.368778 [190/292]\n",
      "loss: 4.353637 [200/292]\n",
      "loss: 4.352874 [210/292]\n",
      "loss: 4.347575 [220/292]\n",
      "loss: 4.272147 [230/292]\n",
      "loss: 4.311107 [240/292]\n",
      "loss: 4.361145 [250/292]\n",
      "loss: 4.326655 [260/292]\n",
      "loss: 4.315040 [270/292]\n",
      "loss: 4.323915 [280/292]\n",
      "loss: 4.326269 [290/292]\n",
      "\n",
      "Test Accuracy: 8.0%\n",
      "Avg Loss: 4.334358\n",
      "\n",
      "Epoch 72\n",
      "-------------------------\n",
      "loss: 4.337315 [10/292]\n",
      "loss: 4.316655 [20/292]\n",
      "loss: 4.309678 [30/292]\n",
      "loss: 4.315535 [40/292]\n",
      "loss: 4.329391 [50/292]\n",
      "loss: 4.320905 [60/292]\n",
      "loss: 4.318380 [70/292]\n",
      "loss: 4.334681 [80/292]\n",
      "loss: 4.321000 [90/292]\n",
      "loss: 4.342639 [100/292]\n",
      "loss: 4.353871 [110/292]\n",
      "loss: 4.309820 [120/292]\n",
      "loss: 4.308444 [130/292]\n",
      "loss: 4.330076 [140/292]\n",
      "loss: 4.325181 [150/292]\n",
      "loss: 4.317473 [160/292]\n",
      "loss: 4.333485 [170/292]\n",
      "loss: 4.353564 [180/292]\n",
      "loss: 4.309449 [190/292]\n",
      "loss: 4.351980 [200/292]\n",
      "loss: 4.346513 [210/292]\n",
      "loss: 4.379332 [220/292]\n",
      "loss: 4.367770 [230/292]\n",
      "loss: 4.316630 [240/292]\n",
      "loss: 4.342305 [250/292]\n",
      "loss: 4.341142 [260/292]\n",
      "loss: 4.305080 [270/292]\n",
      "loss: 4.376546 [280/292]\n",
      "loss: 4.393367 [290/292]\n",
      "\n",
      "Test Accuracy: 7.7%\n",
      "Avg Loss: 4.335188\n",
      "\n",
      "Epoch 73\n",
      "-------------------------\n",
      "loss: 4.345433 [10/292]\n",
      "loss: 4.330239 [20/292]\n",
      "loss: 4.349834 [30/292]\n",
      "loss: 4.349628 [40/292]\n",
      "loss: 4.341620 [50/292]\n",
      "loss: 4.307132 [60/292]\n",
      "loss: 4.337110 [70/292]\n",
      "loss: 4.347470 [80/292]\n",
      "loss: 4.292189 [90/292]\n",
      "loss: 4.345500 [100/292]\n",
      "loss: 4.290003 [110/292]\n",
      "loss: 4.334412 [120/292]\n",
      "loss: 4.327701 [130/292]\n",
      "loss: 4.334568 [140/292]\n",
      "loss: 4.347993 [150/292]\n",
      "loss: 4.352159 [160/292]\n",
      "loss: 4.321731 [170/292]\n",
      "loss: 4.352332 [180/292]\n",
      "loss: 4.333373 [190/292]\n",
      "loss: 4.328565 [200/292]\n",
      "loss: 4.334408 [210/292]\n",
      "loss: 4.302922 [220/292]\n",
      "loss: 4.300344 [230/292]\n",
      "loss: 4.332580 [240/292]\n",
      "loss: 4.313167 [250/292]\n",
      "loss: 4.332339 [260/292]\n",
      "loss: 4.344458 [270/292]\n",
      "loss: 4.308367 [280/292]\n",
      "loss: 4.312491 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.339063\n",
      "\n",
      "Epoch 74\n",
      "-------------------------\n",
      "loss: 4.329989 [10/292]\n",
      "loss: 4.317604 [20/292]\n",
      "loss: 4.338356 [30/292]\n",
      "loss: 4.368064 [40/292]\n",
      "loss: 4.306799 [50/292]\n",
      "loss: 4.339286 [60/292]\n",
      "loss: 4.346781 [70/292]\n",
      "loss: 4.316075 [80/292]\n",
      "loss: 4.348109 [90/292]\n",
      "loss: 4.338153 [100/292]\n",
      "loss: 4.334895 [110/292]\n",
      "loss: 4.368598 [120/292]\n",
      "loss: 4.321683 [130/292]\n",
      "loss: 4.265882 [140/292]\n",
      "loss: 4.293845 [150/292]\n",
      "loss: 4.308920 [160/292]\n",
      "loss: 4.338745 [170/292]\n",
      "loss: 4.371245 [180/292]\n",
      "loss: 4.331404 [190/292]\n",
      "loss: 4.319827 [200/292]\n",
      "loss: 4.368306 [210/292]\n",
      "loss: 4.365294 [220/292]\n",
      "loss: 4.359613 [230/292]\n",
      "loss: 4.361666 [240/292]\n",
      "loss: 4.367807 [250/292]\n",
      "loss: 4.303292 [260/292]\n",
      "loss: 4.344905 [270/292]\n",
      "loss: 4.291173 [280/292]\n",
      "loss: 4.363175 [290/292]\n",
      "\n",
      "Test Accuracy: 7.7%\n",
      "Avg Loss: 4.338744\n",
      "\n",
      "Epoch 75\n",
      "-------------------------\n",
      "loss: 4.337445 [10/292]\n",
      "loss: 4.353498 [20/292]\n",
      "loss: 4.341079 [30/292]\n",
      "loss: 4.334567 [40/292]\n",
      "loss: 4.330705 [50/292]\n",
      "loss: 4.318143 [60/292]\n",
      "loss: 4.364697 [70/292]\n",
      "loss: 4.344343 [80/292]\n",
      "loss: 4.337631 [90/292]\n",
      "loss: 4.345289 [100/292]\n",
      "loss: 4.301485 [110/292]\n",
      "loss: 4.362835 [120/292]\n",
      "loss: 4.350215 [130/292]\n",
      "loss: 4.274478 [140/292]\n",
      "loss: 4.341604 [150/292]\n",
      "loss: 4.358470 [160/292]\n",
      "loss: 4.347249 [170/292]\n",
      "loss: 4.364732 [180/292]\n",
      "loss: 4.311900 [190/292]\n",
      "loss: 4.352169 [200/292]\n",
      "loss: 4.344945 [210/292]\n",
      "loss: 4.333705 [220/292]\n",
      "loss: 4.339936 [230/292]\n",
      "loss: 4.368350 [240/292]\n",
      "loss: 4.290823 [250/292]\n",
      "loss: 4.306597 [260/292]\n",
      "loss: 4.346871 [270/292]\n",
      "loss: 4.342628 [280/292]\n",
      "loss: 4.305131 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.341633\n",
      "\n",
      "Epoch 76\n",
      "-------------------------\n",
      "loss: 4.320644 [10/292]\n",
      "loss: 4.329998 [20/292]\n",
      "loss: 4.322182 [30/292]\n",
      "loss: 4.341190 [40/292]\n",
      "loss: 4.325780 [50/292]\n",
      "loss: 4.366776 [60/292]\n",
      "loss: 4.318743 [70/292]\n",
      "loss: 4.336426 [80/292]\n",
      "loss: 4.332796 [90/292]\n",
      "loss: 4.348572 [100/292]\n",
      "loss: 4.345889 [110/292]\n",
      "loss: 4.348256 [120/292]\n",
      "loss: 4.316310 [130/292]\n",
      "loss: 4.302628 [140/292]\n",
      "loss: 4.339491 [150/292]\n",
      "loss: 4.333509 [160/292]\n",
      "loss: 4.340335 [170/292]\n",
      "loss: 4.286723 [180/292]\n",
      "loss: 4.333827 [190/292]\n",
      "loss: 4.316737 [200/292]\n",
      "loss: 4.344307 [210/292]\n",
      "loss: 4.291068 [220/292]\n",
      "loss: 4.312884 [230/292]\n",
      "loss: 4.329123 [240/292]\n",
      "loss: 4.329604 [250/292]\n",
      "loss: 4.318495 [260/292]\n",
      "loss: 4.336987 [270/292]\n",
      "loss: 4.334728 [280/292]\n",
      "loss: 4.293920 [290/292]\n",
      "\n",
      "Test Accuracy: 7.6%\n",
      "Avg Loss: 4.338469\n",
      "\n",
      "Epoch 77\n",
      "-------------------------\n",
      "loss: 4.348814 [10/292]\n",
      "loss: 4.348985 [20/292]\n",
      "loss: 4.298894 [30/292]\n",
      "loss: 4.331595 [40/292]\n",
      "loss: 4.322121 [50/292]\n",
      "loss: 4.338137 [60/292]\n",
      "loss: 4.320189 [70/292]\n",
      "loss: 4.320904 [80/292]\n",
      "loss: 4.363826 [90/292]\n",
      "loss: 4.332930 [100/292]\n",
      "loss: 4.349239 [110/292]\n",
      "loss: 4.324868 [120/292]\n",
      "loss: 4.343644 [130/292]\n",
      "loss: 4.340665 [140/292]\n",
      "loss: 4.319474 [150/292]\n",
      "loss: 4.326796 [160/292]\n",
      "loss: 4.368242 [170/292]\n",
      "loss: 4.343199 [180/292]\n",
      "loss: 4.362515 [190/292]\n",
      "loss: 4.349242 [200/292]\n",
      "loss: 4.301688 [210/292]\n",
      "loss: 4.361336 [220/292]\n",
      "loss: 4.313618 [230/292]\n",
      "loss: 4.343882 [240/292]\n",
      "loss: 4.328899 [250/292]\n",
      "loss: 4.328942 [260/292]\n",
      "loss: 4.332349 [270/292]\n",
      "loss: 4.366979 [280/292]\n",
      "loss: 4.371636 [290/292]\n",
      "\n",
      "Test Accuracy: 7.6%\n",
      "Avg Loss: 4.338995\n",
      "\n",
      "Epoch 78\n",
      "-------------------------\n",
      "loss: 4.393146 [10/292]\n",
      "loss: 4.294548 [20/292]\n",
      "loss: 4.336753 [30/292]\n",
      "loss: 4.326965 [40/292]\n",
      "loss: 4.283911 [50/292]\n",
      "loss: 4.324140 [60/292]\n",
      "loss: 4.338865 [70/292]\n",
      "loss: 4.298376 [80/292]\n",
      "loss: 4.305133 [90/292]\n",
      "loss: 4.304110 [100/292]\n",
      "loss: 4.322821 [110/292]\n",
      "loss: 4.324739 [120/292]\n",
      "loss: 4.327634 [130/292]\n",
      "loss: 4.311542 [140/292]\n",
      "loss: 4.375653 [150/292]\n",
      "loss: 4.347059 [160/292]\n",
      "loss: 4.334156 [170/292]\n",
      "loss: 4.280481 [180/292]\n",
      "loss: 4.346852 [190/292]\n",
      "loss: 4.386009 [200/292]\n",
      "loss: 4.320454 [210/292]\n",
      "loss: 4.340961 [220/292]\n",
      "loss: 4.317159 [230/292]\n",
      "loss: 4.357333 [240/292]\n",
      "loss: 4.319354 [250/292]\n",
      "loss: 4.358358 [260/292]\n",
      "loss: 4.331285 [270/292]\n",
      "loss: 4.335927 [280/292]\n",
      "loss: 4.376284 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.336447\n",
      "\n",
      "Epoch 79\n",
      "-------------------------\n",
      "loss: 4.289245 [10/292]\n",
      "loss: 4.339832 [20/292]\n",
      "loss: 4.361191 [30/292]\n",
      "loss: 4.361196 [40/292]\n",
      "loss: 4.324467 [50/292]\n",
      "loss: 4.292569 [60/292]\n",
      "loss: 4.358510 [70/292]\n",
      "loss: 4.322208 [80/292]\n",
      "loss: 4.314612 [90/292]\n",
      "loss: 4.332778 [100/292]\n",
      "loss: 4.322924 [110/292]\n",
      "loss: 4.322829 [120/292]\n",
      "loss: 4.347495 [130/292]\n",
      "loss: 4.337677 [140/292]\n",
      "loss: 4.295800 [150/292]\n",
      "loss: 4.352129 [160/292]\n",
      "loss: 4.361974 [170/292]\n",
      "loss: 4.346410 [180/292]\n",
      "loss: 4.305828 [190/292]\n",
      "loss: 4.354745 [200/292]\n",
      "loss: 4.308677 [210/292]\n",
      "loss: 4.356735 [220/292]\n",
      "loss: 4.319045 [230/292]\n",
      "loss: 4.323932 [240/292]\n",
      "loss: 4.358593 [250/292]\n",
      "loss: 4.330320 [260/292]\n",
      "loss: 4.344365 [270/292]\n",
      "loss: 4.318308 [280/292]\n",
      "loss: 4.314778 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.336588\n",
      "\n",
      "Epoch 80\n",
      "-------------------------\n",
      "loss: 4.269629 [10/292]\n",
      "loss: 4.294883 [20/292]\n",
      "loss: 4.332666 [30/292]\n",
      "loss: 4.349924 [40/292]\n",
      "loss: 4.372761 [50/292]\n",
      "loss: 4.291632 [60/292]\n",
      "loss: 4.304062 [70/292]\n",
      "loss: 4.342431 [80/292]\n",
      "loss: 4.347198 [90/292]\n",
      "loss: 4.354080 [100/292]\n",
      "loss: 4.337856 [110/292]\n",
      "loss: 4.274784 [120/292]\n",
      "loss: 4.348766 [130/292]\n",
      "loss: 4.330159 [140/292]\n",
      "loss: 4.355538 [150/292]\n",
      "loss: 4.355984 [160/292]\n",
      "loss: 4.332030 [170/292]\n",
      "loss: 4.365582 [180/292]\n",
      "loss: 4.317557 [190/292]\n",
      "loss: 4.357298 [200/292]\n",
      "loss: 4.330991 [210/292]\n",
      "loss: 4.341736 [220/292]\n",
      "loss: 4.315830 [230/292]\n",
      "loss: 4.298546 [240/292]\n",
      "loss: 4.342871 [250/292]\n",
      "loss: 4.366912 [260/292]\n",
      "loss: 4.370238 [270/292]\n",
      "loss: 4.302607 [280/292]\n",
      "loss: 4.344737 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.335131\n",
      "\n",
      "Epoch 81\n",
      "-------------------------\n",
      "loss: 4.357594 [10/292]\n",
      "loss: 4.307172 [20/292]\n",
      "loss: 4.331741 [30/292]\n",
      "loss: 4.342343 [40/292]\n",
      "loss: 4.329793 [50/292]\n",
      "loss: 4.334101 [60/292]\n",
      "loss: 4.353299 [70/292]\n",
      "loss: 4.368194 [80/292]\n",
      "loss: 4.332268 [90/292]\n",
      "loss: 4.309698 [100/292]\n",
      "loss: 4.333046 [110/292]\n",
      "loss: 4.353710 [120/292]\n",
      "loss: 4.351224 [130/292]\n",
      "loss: 4.335155 [140/292]\n",
      "loss: 4.364611 [150/292]\n",
      "loss: 4.351069 [160/292]\n",
      "loss: 4.329218 [170/292]\n",
      "loss: 4.339962 [180/292]\n",
      "loss: 4.383332 [190/292]\n",
      "loss: 4.390173 [200/292]\n",
      "loss: 4.293520 [210/292]\n",
      "loss: 4.357168 [220/292]\n",
      "loss: 4.310538 [230/292]\n",
      "loss: 4.292584 [240/292]\n",
      "loss: 4.362666 [250/292]\n",
      "loss: 4.352668 [260/292]\n",
      "loss: 4.355847 [270/292]\n",
      "loss: 4.308861 [280/292]\n",
      "loss: 4.360807 [290/292]\n",
      "\n",
      "Test Accuracy: 7.8%\n",
      "Avg Loss: 4.337831\n",
      "\n",
      "Epoch 82\n",
      "-------------------------\n",
      "loss: 4.330868 [10/292]\n",
      "loss: 4.323747 [20/292]\n",
      "loss: 4.313347 [30/292]\n",
      "loss: 4.315405 [40/292]\n",
      "loss: 4.334000 [50/292]\n",
      "loss: 4.306047 [60/292]\n",
      "loss: 4.339726 [70/292]\n",
      "loss: 4.342371 [80/292]\n",
      "loss: 4.294893 [90/292]\n",
      "loss: 4.348454 [100/292]\n",
      "loss: 4.323283 [110/292]\n",
      "loss: 4.355768 [120/292]\n",
      "loss: 4.319710 [130/292]\n",
      "loss: 4.354087 [140/292]\n",
      "loss: 4.331741 [150/292]\n",
      "loss: 4.347427 [160/292]\n",
      "loss: 4.337066 [170/292]\n",
      "loss: 4.341320 [180/292]\n",
      "loss: 4.340590 [190/292]\n",
      "loss: 4.326711 [200/292]\n",
      "loss: 4.314977 [210/292]\n",
      "loss: 4.360103 [220/292]\n",
      "loss: 4.314422 [230/292]\n",
      "loss: 4.332061 [240/292]\n",
      "loss: 4.313975 [250/292]\n",
      "loss: 4.329463 [260/292]\n",
      "loss: 4.342336 [270/292]\n",
      "loss: 4.343090 [280/292]\n",
      "loss: 4.334182 [290/292]\n",
      "\n",
      "Test Accuracy: 8.4%\n",
      "Avg Loss: 4.332368\n",
      "\n",
      "Epoch 83\n",
      "-------------------------\n",
      "loss: 4.356526 [10/292]\n",
      "loss: 4.331820 [20/292]\n",
      "loss: 4.383451 [30/292]\n",
      "loss: 4.323979 [40/292]\n",
      "loss: 4.331395 [50/292]\n",
      "loss: 4.361086 [60/292]\n",
      "loss: 4.333614 [70/292]\n",
      "loss: 4.336782 [80/292]\n",
      "loss: 4.316196 [90/292]\n",
      "loss: 4.348183 [100/292]\n",
      "loss: 4.357106 [110/292]\n",
      "loss: 4.362677 [120/292]\n",
      "loss: 4.310575 [130/292]\n",
      "loss: 4.322486 [140/292]\n",
      "loss: 4.312294 [150/292]\n",
      "loss: 4.359513 [160/292]\n",
      "loss: 4.305414 [170/292]\n",
      "loss: 4.347304 [180/292]\n",
      "loss: 4.360025 [190/292]\n",
      "loss: 4.333711 [200/292]\n",
      "loss: 4.320199 [210/292]\n",
      "loss: 4.352232 [220/292]\n",
      "loss: 4.311650 [230/292]\n",
      "loss: 4.322170 [240/292]\n",
      "loss: 4.332209 [250/292]\n",
      "loss: 4.350945 [260/292]\n",
      "loss: 4.336280 [270/292]\n",
      "loss: 4.299852 [280/292]\n",
      "loss: 4.333070 [290/292]\n",
      "\n",
      "Test Accuracy: 8.1%\n",
      "Avg Loss: 4.332454\n",
      "\n",
      "Epoch 84\n",
      "-------------------------\n",
      "loss: 4.341115 [10/292]\n",
      "loss: 4.259934 [20/292]\n",
      "loss: 4.309475 [30/292]\n",
      "loss: 4.320168 [40/292]\n",
      "loss: 4.306631 [50/292]\n",
      "loss: 4.346067 [60/292]\n",
      "loss: 4.372613 [70/292]\n",
      "loss: 4.307229 [80/292]\n",
      "loss: 4.359504 [90/292]\n",
      "loss: 4.312593 [100/292]\n",
      "loss: 4.292577 [110/292]\n",
      "loss: 4.350361 [120/292]\n",
      "loss: 4.282004 [130/292]\n",
      "loss: 4.289725 [140/292]\n",
      "loss: 4.354002 [150/292]\n",
      "loss: 4.352255 [160/292]\n",
      "loss: 4.357522 [170/292]\n",
      "loss: 4.333086 [180/292]\n",
      "loss: 4.316619 [190/292]\n",
      "loss: 4.350113 [200/292]\n",
      "loss: 4.332327 [210/292]\n",
      "loss: 4.354879 [220/292]\n",
      "loss: 4.335571 [230/292]\n",
      "loss: 4.338828 [240/292]\n",
      "loss: 4.314095 [250/292]\n",
      "loss: 4.357700 [260/292]\n",
      "loss: 4.298259 [270/292]\n",
      "loss: 4.314711 [280/292]\n",
      "loss: 4.311488 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.337884\n",
      "\n",
      "Epoch 85\n",
      "-------------------------\n",
      "loss: 4.321323 [10/292]\n",
      "loss: 4.351967 [20/292]\n",
      "loss: 4.344667 [30/292]\n",
      "loss: 4.317970 [40/292]\n",
      "loss: 4.327032 [50/292]\n",
      "loss: 4.340695 [60/292]\n",
      "loss: 4.313509 [70/292]\n",
      "loss: 4.336458 [80/292]\n",
      "loss: 4.336054 [90/292]\n",
      "loss: 4.344540 [100/292]\n",
      "loss: 4.286619 [110/292]\n",
      "loss: 4.344432 [120/292]\n",
      "loss: 4.332370 [130/292]\n",
      "loss: 4.336826 [140/292]\n",
      "loss: 4.314191 [150/292]\n",
      "loss: 4.319538 [160/292]\n",
      "loss: 4.343734 [170/292]\n",
      "loss: 4.321274 [180/292]\n",
      "loss: 4.351208 [190/292]\n",
      "loss: 4.339335 [200/292]\n",
      "loss: 4.344798 [210/292]\n",
      "loss: 4.328939 [220/292]\n",
      "loss: 4.319695 [230/292]\n",
      "loss: 4.312007 [240/292]\n",
      "loss: 4.330126 [250/292]\n",
      "loss: 4.357823 [260/292]\n",
      "loss: 4.336583 [270/292]\n",
      "loss: 4.372721 [280/292]\n",
      "loss: 4.335392 [290/292]\n",
      "\n",
      "Test Accuracy: 8.0%\n",
      "Avg Loss: 4.335798\n",
      "\n",
      "Epoch 86\n",
      "-------------------------\n",
      "loss: 4.323946 [10/292]\n",
      "loss: 4.304142 [20/292]\n",
      "loss: 4.325151 [30/292]\n",
      "loss: 4.316707 [40/292]\n",
      "loss: 4.302306 [50/292]\n",
      "loss: 4.371223 [60/292]\n",
      "loss: 4.350763 [70/292]\n",
      "loss: 4.343788 [80/292]\n",
      "loss: 4.340962 [90/292]\n",
      "loss: 4.382979 [100/292]\n",
      "loss: 4.313720 [110/292]\n",
      "loss: 4.301078 [120/292]\n",
      "loss: 4.320113 [130/292]\n",
      "loss: 4.378466 [140/292]\n",
      "loss: 4.316166 [150/292]\n",
      "loss: 4.344061 [160/292]\n",
      "loss: 4.313489 [170/292]\n",
      "loss: 4.311110 [180/292]\n",
      "loss: 4.344982 [190/292]\n",
      "loss: 4.366179 [200/292]\n",
      "loss: 4.345438 [210/292]\n",
      "loss: 4.355303 [220/292]\n",
      "loss: 4.359140 [230/292]\n",
      "loss: 4.276871 [240/292]\n",
      "loss: 4.292286 [250/292]\n",
      "loss: 4.329624 [260/292]\n",
      "loss: 4.367936 [270/292]\n",
      "loss: 4.360034 [280/292]\n",
      "loss: 4.334774 [290/292]\n",
      "\n",
      "Test Accuracy: 7.8%\n",
      "Avg Loss: 4.336697\n",
      "\n",
      "Epoch 87\n",
      "-------------------------\n",
      "loss: 4.328340 [10/292]\n",
      "loss: 4.337098 [20/292]\n",
      "loss: 4.291099 [30/292]\n",
      "loss: 4.359526 [40/292]\n",
      "loss: 4.348938 [50/292]\n",
      "loss: 4.324701 [60/292]\n",
      "loss: 4.372003 [70/292]\n",
      "loss: 4.311202 [80/292]\n",
      "loss: 4.339015 [90/292]\n",
      "loss: 4.370045 [100/292]\n",
      "loss: 4.334231 [110/292]\n",
      "loss: 4.330822 [120/292]\n",
      "loss: 4.335343 [130/292]\n",
      "loss: 4.356498 [140/292]\n",
      "loss: 4.344569 [150/292]\n",
      "loss: 4.347675 [160/292]\n",
      "loss: 4.361179 [170/292]\n",
      "loss: 4.322544 [180/292]\n",
      "loss: 4.314022 [190/292]\n",
      "loss: 4.343185 [200/292]\n",
      "loss: 4.320061 [210/292]\n",
      "loss: 4.321357 [220/292]\n",
      "loss: 4.374153 [230/292]\n",
      "loss: 4.351092 [240/292]\n",
      "loss: 4.343616 [250/292]\n",
      "loss: 4.314108 [260/292]\n",
      "loss: 4.339017 [270/292]\n",
      "loss: 4.355836 [280/292]\n",
      "loss: 4.259888 [290/292]\n",
      "\n",
      "Test Accuracy: 7.5%\n",
      "Avg Loss: 4.339721\n",
      "\n",
      "Epoch 88\n",
      "-------------------------\n",
      "loss: 4.316225 [10/292]\n",
      "loss: 4.340421 [20/292]\n",
      "loss: 4.329114 [30/292]\n",
      "loss: 4.297990 [40/292]\n",
      "loss: 4.351244 [50/292]\n",
      "loss: 4.337212 [60/292]\n",
      "loss: 4.360698 [70/292]\n",
      "loss: 4.308817 [80/292]\n",
      "loss: 4.332790 [90/292]\n",
      "loss: 4.312396 [100/292]\n",
      "loss: 4.304502 [110/292]\n",
      "loss: 4.330046 [120/292]\n",
      "loss: 4.363685 [130/292]\n",
      "loss: 4.339298 [140/292]\n",
      "loss: 4.343344 [150/292]\n",
      "loss: 4.327912 [160/292]\n",
      "loss: 4.375073 [170/292]\n",
      "loss: 4.328070 [180/292]\n",
      "loss: 4.312987 [190/292]\n",
      "loss: 4.329070 [200/292]\n",
      "loss: 4.303722 [210/292]\n",
      "loss: 4.355086 [220/292]\n",
      "loss: 4.314121 [230/292]\n",
      "loss: 4.324507 [240/292]\n",
      "loss: 4.330999 [250/292]\n",
      "loss: 4.325696 [260/292]\n",
      "loss: 4.329150 [270/292]\n",
      "loss: 4.383511 [280/292]\n",
      "loss: 4.352478 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.337167\n",
      "\n",
      "Epoch 89\n",
      "-------------------------\n",
      "loss: 4.371361 [10/292]\n",
      "loss: 4.347972 [20/292]\n",
      "loss: 4.329710 [30/292]\n",
      "loss: 4.345592 [40/292]\n",
      "loss: 4.302979 [50/292]\n",
      "loss: 4.321835 [60/292]\n",
      "loss: 4.324485 [70/292]\n",
      "loss: 4.355382 [80/292]\n",
      "loss: 4.335005 [90/292]\n",
      "loss: 4.373704 [100/292]\n",
      "loss: 4.345100 [110/292]\n",
      "loss: 4.355410 [120/292]\n",
      "loss: 4.367884 [130/292]\n",
      "loss: 4.319201 [140/292]\n",
      "loss: 4.337106 [150/292]\n",
      "loss: 4.332498 [160/292]\n",
      "loss: 4.320907 [170/292]\n",
      "loss: 4.305093 [180/292]\n",
      "loss: 4.353059 [190/292]\n",
      "loss: 4.353709 [200/292]\n",
      "loss: 4.344193 [210/292]\n",
      "loss: 4.338245 [220/292]\n",
      "loss: 4.307414 [230/292]\n",
      "loss: 4.299633 [240/292]\n",
      "loss: 4.339195 [250/292]\n",
      "loss: 4.312403 [260/292]\n",
      "loss: 4.351552 [270/292]\n",
      "loss: 4.364804 [280/292]\n",
      "loss: 4.328767 [290/292]\n",
      "\n",
      "Test Accuracy: 8.0%\n",
      "Avg Loss: 4.335840\n",
      "\n",
      "Epoch 90\n",
      "-------------------------\n",
      "loss: 4.272229 [10/292]\n",
      "loss: 4.312383 [20/292]\n",
      "loss: 4.361863 [30/292]\n",
      "loss: 4.306134 [40/292]\n",
      "loss: 4.369317 [50/292]\n",
      "loss: 4.306841 [60/292]\n",
      "loss: 4.378558 [70/292]\n",
      "loss: 4.344429 [80/292]\n",
      "loss: 4.348685 [90/292]\n",
      "loss: 4.341228 [100/292]\n",
      "loss: 4.354265 [110/292]\n",
      "loss: 4.326487 [120/292]\n",
      "loss: 4.327747 [130/292]\n",
      "loss: 4.324801 [140/292]\n",
      "loss: 4.329796 [150/292]\n",
      "loss: 4.344718 [160/292]\n",
      "loss: 4.348888 [170/292]\n",
      "loss: 4.367193 [180/292]\n",
      "loss: 4.325880 [190/292]\n",
      "loss: 4.360280 [200/292]\n",
      "loss: 4.374296 [210/292]\n",
      "loss: 4.338956 [220/292]\n",
      "loss: 4.351988 [230/292]\n",
      "loss: 4.350946 [240/292]\n",
      "loss: 4.366576 [250/292]\n",
      "loss: 4.343987 [260/292]\n",
      "loss: 4.339129 [270/292]\n",
      "loss: 4.346272 [280/292]\n",
      "loss: 4.329325 [290/292]\n",
      "\n",
      "Test Accuracy: 7.9%\n",
      "Avg Loss: 4.337535\n",
      "\n",
      "Epoch 91\n",
      "-------------------------\n",
      "loss: 4.309497 [10/292]\n",
      "loss: 4.339754 [20/292]\n",
      "loss: 4.331395 [30/292]\n",
      "loss: 4.335810 [40/292]\n",
      "loss: 4.308867 [50/292]\n",
      "loss: 4.305934 [60/292]\n",
      "loss: 4.291200 [70/292]\n",
      "loss: 4.353069 [80/292]\n",
      "loss: 4.323232 [90/292]\n",
      "loss: 4.341141 [100/292]\n",
      "loss: 4.336440 [110/292]\n",
      "loss: 4.361664 [120/292]\n",
      "loss: 4.336189 [130/292]\n",
      "loss: 4.340399 [140/292]\n",
      "loss: 4.324102 [150/292]\n",
      "loss: 4.254185 [160/292]\n",
      "loss: 4.334055 [170/292]\n",
      "loss: 4.385541 [180/292]\n",
      "loss: 4.330585 [190/292]\n",
      "loss: 4.335942 [200/292]\n",
      "loss: 4.352966 [210/292]\n",
      "loss: 4.299624 [220/292]\n",
      "loss: 4.344722 [230/292]\n",
      "loss: 4.321067 [240/292]\n",
      "loss: 4.367427 [250/292]\n",
      "loss: 4.364302 [260/292]\n",
      "loss: 4.331720 [270/292]\n",
      "loss: 4.352415 [280/292]\n",
      "loss: 4.310784 [290/292]\n",
      "\n",
      "Test Accuracy: 7.8%\n",
      "Avg Loss: 4.338069\n",
      "\n",
      "Epoch 92\n",
      "-------------------------\n",
      "loss: 4.327724 [10/292]\n",
      "loss: 4.305049 [20/292]\n",
      "loss: 4.328170 [30/292]\n",
      "loss: 4.343740 [40/292]\n",
      "loss: 4.326617 [50/292]\n",
      "loss: 4.355993 [60/292]\n",
      "loss: 4.306662 [70/292]\n",
      "loss: 4.329048 [80/292]\n",
      "loss: 4.323385 [90/292]\n",
      "loss: 4.336556 [100/292]\n",
      "loss: 4.325025 [110/292]\n",
      "loss: 4.348507 [120/292]\n",
      "loss: 4.287490 [130/292]\n",
      "loss: 4.378886 [140/292]\n",
      "loss: 4.357677 [150/292]\n",
      "loss: 4.310680 [160/292]\n",
      "loss: 4.288377 [170/292]\n",
      "loss: 4.366691 [180/292]\n",
      "loss: 4.286392 [190/292]\n",
      "loss: 4.353391 [200/292]\n",
      "loss: 4.313059 [210/292]\n",
      "loss: 4.306027 [220/292]\n",
      "loss: 4.352554 [230/292]\n",
      "loss: 4.358891 [240/292]\n",
      "loss: 4.351513 [250/292]\n",
      "loss: 4.327781 [260/292]\n",
      "loss: 4.330780 [270/292]\n",
      "loss: 4.361651 [280/292]\n",
      "loss: 4.326743 [290/292]\n",
      "\n",
      "Test Accuracy: 7.7%\n",
      "Avg Loss: 4.339512\n",
      "\n",
      "Epoch 93\n",
      "-------------------------\n",
      "loss: 4.327288 [10/292]\n",
      "loss: 4.351913 [20/292]\n",
      "loss: 4.376309 [30/292]\n",
      "loss: 4.337408 [40/292]\n",
      "loss: 4.334288 [50/292]\n",
      "loss: 4.336557 [60/292]\n",
      "loss: 4.347473 [70/292]\n",
      "loss: 4.332990 [80/292]\n",
      "loss: 4.320449 [90/292]\n",
      "loss: 4.285286 [100/292]\n",
      "loss: 4.380277 [110/292]\n",
      "loss: 4.386994 [120/292]\n",
      "loss: 4.346766 [130/292]\n",
      "loss: 4.329358 [140/292]\n",
      "loss: 4.329673 [150/292]\n",
      "loss: 4.350120 [160/292]\n",
      "loss: 4.302338 [170/292]\n",
      "loss: 4.331381 [180/292]\n",
      "loss: 4.362803 [190/292]\n",
      "loss: 4.352738 [200/292]\n",
      "loss: 4.314925 [210/292]\n",
      "loss: 4.299129 [220/292]\n",
      "loss: 4.341166 [230/292]\n",
      "loss: 4.360005 [240/292]\n",
      "loss: 4.308024 [250/292]\n",
      "loss: 4.359803 [260/292]\n",
      "loss: 4.358988 [270/292]\n",
      "loss: 4.349254 [280/292]\n",
      "loss: 4.359411 [290/292]\n",
      "\n",
      "Test Accuracy: 7.3%\n",
      "Avg Loss: 4.342762\n",
      "\n",
      "Epoch 94\n",
      "-------------------------\n",
      "loss: 4.360299 [10/292]\n",
      "loss: 4.328657 [20/292]\n",
      "loss: 4.360522 [30/292]\n",
      "loss: 4.352403 [40/292]\n",
      "loss: 4.358493 [50/292]\n",
      "loss: 4.321329 [60/292]\n",
      "loss: 4.345246 [70/292]\n",
      "loss: 4.344853 [80/292]\n",
      "loss: 4.323439 [90/292]\n",
      "loss: 4.345039 [100/292]\n",
      "loss: 4.367558 [110/292]\n",
      "loss: 4.354150 [120/292]\n",
      "loss: 4.353472 [130/292]\n",
      "loss: 4.313775 [140/292]\n",
      "loss: 4.323314 [150/292]\n",
      "loss: 4.363966 [160/292]\n",
      "loss: 4.326715 [170/292]\n",
      "loss: 4.376095 [180/292]\n",
      "loss: 4.364739 [190/292]\n",
      "loss: 4.317967 [200/292]\n",
      "loss: 4.298890 [210/292]\n",
      "loss: 4.329576 [220/292]\n",
      "loss: 4.288867 [230/292]\n",
      "loss: 4.337641 [240/292]\n",
      "loss: 4.352652 [250/292]\n",
      "loss: 4.317832 [260/292]\n",
      "loss: 4.337166 [270/292]\n",
      "loss: 4.325723 [280/292]\n",
      "loss: 4.353251 [290/292]\n",
      "\n",
      "Test Accuracy: 7.6%\n",
      "Avg Loss: 4.339905\n",
      "\n",
      "Epoch 95\n",
      "-------------------------\n",
      "loss: 4.354428 [10/292]\n",
      "loss: 4.324208 [20/292]\n",
      "loss: 4.350224 [30/292]\n",
      "loss: 4.290260 [40/292]\n",
      "loss: 4.341012 [50/292]\n",
      "loss: 4.332190 [60/292]\n",
      "loss: 4.337008 [70/292]\n",
      "loss: 4.329850 [80/292]\n",
      "loss: 4.358016 [90/292]\n",
      "loss: 4.383646 [100/292]\n",
      "loss: 4.337841 [110/292]\n",
      "loss: 4.358804 [120/292]\n",
      "loss: 4.322676 [130/292]\n",
      "loss: 4.285489 [140/292]\n",
      "loss: 4.326545 [150/292]\n",
      "loss: 4.273374 [160/292]\n",
      "loss: 4.323267 [170/292]\n",
      "loss: 4.364615 [180/292]\n",
      "loss: 4.352599 [190/292]\n",
      "loss: 4.352541 [200/292]\n",
      "loss: 4.384186 [210/292]\n",
      "loss: 4.335905 [220/292]\n",
      "loss: 4.321052 [230/292]\n",
      "loss: 4.345712 [240/292]\n",
      "loss: 4.352730 [250/292]\n",
      "loss: 4.295554 [260/292]\n",
      "loss: 4.375766 [270/292]\n",
      "loss: 4.321343 [280/292]\n",
      "loss: 4.324798 [290/292]\n",
      "\n",
      "Test Accuracy: 7.2%\n",
      "Avg Loss: 4.344559\n",
      "\n",
      "Epoch 96\n",
      "-------------------------\n",
      "loss: 4.304832 [10/292]\n",
      "loss: 4.314383 [20/292]\n",
      "loss: 4.327683 [30/292]\n",
      "loss: 4.322109 [40/292]\n",
      "loss: 4.313530 [50/292]\n",
      "loss: 4.352286 [60/292]\n",
      "loss: 4.314105 [70/292]\n",
      "loss: 4.347351 [80/292]\n",
      "loss: 4.352398 [90/292]\n",
      "loss: 4.383812 [100/292]\n",
      "loss: 4.318593 [110/292]\n",
      "loss: 4.328506 [120/292]\n",
      "loss: 4.342180 [130/292]\n",
      "loss: 4.341874 [140/292]\n",
      "loss: 4.345003 [150/292]\n",
      "loss: 4.336527 [160/292]\n",
      "loss: 4.329149 [170/292]\n",
      "loss: 4.352638 [180/292]\n",
      "loss: 4.322262 [190/292]\n",
      "loss: 4.335628 [200/292]\n",
      "loss: 4.326555 [210/292]\n",
      "loss: 4.349747 [220/292]\n",
      "loss: 4.344735 [230/292]\n",
      "loss: 4.329377 [240/292]\n",
      "loss: 4.344480 [250/292]\n",
      "loss: 4.338240 [260/292]\n",
      "loss: 4.345102 [270/292]\n",
      "loss: 4.315404 [280/292]\n",
      "loss: 4.359211 [290/292]\n",
      "\n",
      "Test Accuracy: 7.3%\n",
      "Avg Loss: 4.342867\n",
      "\n",
      "Epoch 97\n",
      "-------------------------\n",
      "loss: 4.360434 [10/292]\n",
      "loss: 4.365737 [20/292]\n",
      "loss: 4.297054 [30/292]\n",
      "loss: 4.344899 [40/292]\n",
      "loss: 4.329220 [50/292]\n",
      "loss: 4.352310 [60/292]\n",
      "loss: 4.346593 [70/292]\n",
      "loss: 4.352499 [80/292]\n",
      "loss: 4.358730 [90/292]\n",
      "loss: 4.319446 [100/292]\n",
      "loss: 4.347079 [110/292]\n",
      "loss: 4.329258 [120/292]\n",
      "loss: 4.337468 [130/292]\n",
      "loss: 4.368176 [140/292]\n",
      "loss: 4.343986 [150/292]\n",
      "loss: 4.368053 [160/292]\n",
      "loss: 4.323732 [170/292]\n",
      "loss: 4.335027 [180/292]\n",
      "loss: 4.329313 [190/292]\n",
      "loss: 4.331709 [200/292]\n",
      "loss: 4.345565 [210/292]\n",
      "loss: 4.360120 [220/292]\n",
      "loss: 4.344281 [230/292]\n",
      "loss: 4.331770 [240/292]\n",
      "loss: 4.374558 [250/292]\n",
      "loss: 4.359680 [260/292]\n",
      "loss: 4.354382 [270/292]\n",
      "loss: 4.344694 [280/292]\n",
      "loss: 4.383755 [290/292]\n",
      "\n",
      "Test Accuracy: 7.2%\n",
      "Avg Loss: 4.344550\n",
      "\n",
      "Epoch 98\n",
      "-------------------------\n",
      "loss: 4.325041 [10/292]\n",
      "loss: 4.309929 [20/292]\n",
      "loss: 4.291990 [30/292]\n",
      "loss: 4.336948 [40/292]\n",
      "loss: 4.313740 [50/292]\n",
      "loss: 4.352281 [60/292]\n",
      "loss: 4.341667 [70/292]\n",
      "loss: 4.381782 [80/292]\n",
      "loss: 4.330886 [90/292]\n",
      "loss: 4.365531 [100/292]\n",
      "loss: 4.363205 [110/292]\n",
      "loss: 4.368409 [120/292]\n",
      "loss: 4.352874 [130/292]\n",
      "loss: 4.352584 [140/292]\n",
      "loss: 4.305915 [150/292]\n",
      "loss: 4.376145 [160/292]\n",
      "loss: 4.360409 [170/292]\n",
      "loss: 4.305930 [180/292]\n",
      "loss: 4.345005 [190/292]\n",
      "loss: 4.321887 [200/292]\n",
      "loss: 4.349593 [210/292]\n",
      "loss: 4.354492 [220/292]\n",
      "loss: 4.344880 [230/292]\n",
      "loss: 4.338222 [240/292]\n",
      "loss: 4.352232 [250/292]\n",
      "loss: 4.387846 [260/292]\n",
      "loss: 4.341825 [270/292]\n",
      "loss: 4.328415 [280/292]\n",
      "loss: 4.360538 [290/292]\n",
      "\n",
      "Test Accuracy: 7.1%\n",
      "Avg Loss: 4.344560\n",
      "\n",
      "Epoch 99\n",
      "-------------------------\n",
      "loss: 4.340757 [10/292]\n",
      "loss: 4.336926 [20/292]\n",
      "loss: 4.338355 [30/292]\n",
      "loss: 4.360173 [40/292]\n",
      "loss: 4.329733 [50/292]\n",
      "loss: 4.341179 [60/292]\n",
      "loss: 4.359132 [70/292]\n",
      "loss: 4.340817 [80/292]\n",
      "loss: 4.328484 [90/292]\n",
      "loss: 4.333558 [100/292]\n",
      "loss: 4.309866 [110/292]\n",
      "loss: 4.367076 [120/292]\n",
      "loss: 4.353410 [130/292]\n",
      "loss: 4.330365 [140/292]\n",
      "loss: 4.360354 [150/292]\n",
      "loss: 4.359623 [160/292]\n",
      "loss: 4.365326 [170/292]\n",
      "loss: 4.343532 [180/292]\n",
      "loss: 4.360689 [190/292]\n",
      "loss: 4.347421 [200/292]\n",
      "loss: 4.351139 [210/292]\n",
      "loss: 4.368281 [220/292]\n",
      "loss: 4.329286 [230/292]\n",
      "loss: 4.325300 [240/292]\n",
      "loss: 4.329135 [250/292]\n",
      "loss: 4.343041 [260/292]\n",
      "loss: 4.376003 [270/292]\n",
      "loss: 4.331080 [280/292]\n",
      "loss: 4.321770 [290/292]\n",
      "\n",
      "Test Accuracy: 7.1%\n",
      "Avg Loss: 4.346458\n",
      "\n",
      "Epoch 100\n",
      "-------------------------\n",
      "loss: 4.333008 [10/292]\n",
      "loss: 4.329993 [20/292]\n",
      "loss: 4.306715 [30/292]\n",
      "loss: 4.382839 [40/292]\n",
      "loss: 4.352766 [50/292]\n",
      "loss: 4.344629 [60/292]\n",
      "loss: 4.349813 [70/292]\n",
      "loss: 4.327050 [80/292]\n",
      "loss: 4.335070 [90/292]\n",
      "loss: 4.327621 [100/292]\n",
      "loss: 4.367265 [110/292]\n",
      "loss: 4.362892 [120/292]\n",
      "loss: 4.352456 [130/292]\n",
      "loss: 4.331743 [140/292]\n",
      "loss: 4.329156 [150/292]\n",
      "loss: 4.313389 [160/292]\n",
      "loss: 4.318433 [170/292]\n",
      "loss: 4.314086 [180/292]\n",
      "loss: 4.344884 [190/292]\n",
      "loss: 4.328281 [200/292]\n",
      "loss: 4.346417 [210/292]\n",
      "loss: 4.376261 [220/292]\n",
      "loss: 4.368314 [230/292]\n",
      "loss: 4.351813 [240/292]\n",
      "loss: 4.345419 [250/292]\n",
      "loss: 4.315944 [260/292]\n",
      "loss: 4.344823 [270/292]\n",
      "loss: 4.328570 [280/292]\n",
      "loss: 4.360751 [290/292]\n",
      "\n",
      "Test Accuracy: 7.0%\n",
      "Avg Loss: 4.345955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "batch_size = 128\n",
    "epoches = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=2 * batch_size)\n",
    "\n",
    "for i in range(epoches):\n",
    "    print(f\"Epoch {i + 1}\\n{'-' * 25}\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0058bde-e04d-4690-8c47-bf9e4109557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/tiny_weights.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
